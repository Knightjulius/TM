{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Text Mining Emma Vonk, Julius Ruijgrok\n",
    "## Question 1 The tutorial classifies between only four categories of the 20newsgroups data set. Change your script so that it addresses all 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1 of text mining\n",
    "\n",
    "# code from https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def load_dataset(vectorizer, verbose=False, remove=()):\n",
    "    \"\"\"Load and vectorize the 20 newsgroups dataset using the specified vectorizer.\"\"\"\n",
    "    \n",
    "    data_train = fetch_20newsgroups(\n",
    "        subset=\"train\",\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "\n",
    "    data_test = fetch_20newsgroups(\n",
    "        subset=\"test\",\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "\n",
    "    # Order of labels in `target_names` can be different from `categories`\n",
    "    target_names = data_train.target_names\n",
    "\n",
    "    # Split target in a training set and a test set\n",
    "    y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "    # Extracting features from the training data using the specified vectorizer\n",
    "    t0 = time()\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "    duration_train = time() - t0\n",
    "\n",
    "    # Extracting features from the test data using the same vectorizer\n",
    "    t0 = time()\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    duration_test = time() - t0\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    if verbose:\n",
    "        # Compute size of loaded data\n",
    "        data_train_size_mb = size_mb(data_train.data)\n",
    "        data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "        print(f\"{len(data_train.data)} documents - {data_train_size_mb:.2f}MB (training set)\")\n",
    "        print(f\"{len(data_test.data)} documents - {data_test_size_mb:.2f}MB (test set)\")\n",
    "        print(f\"{len(target_names)} categories\")\n",
    "        print(f\"Vectorize training done in {duration_train:.3f}s at {data_train_size_mb / duration_train:.3f}MB/s\")\n",
    "        print(f\"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}\")\n",
    "        print(f\"Vectorize testing done in {duration_test:.3f}s at {data_test_size_mb / duration_test:.3f}MB/s\")\n",
    "        print(f\"n_samples: {X_test.shape[0]}, n_features: {X_test.shape[1]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, feature_names, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different vectorizers to be used later\n",
    "count_vectorizer = CountVectorizer()\n",
    "tf_vectorizer = TfidfVectorizer(sublinear_tf=False,use_idf=False, max_df=0.5, min_df=5, stop_words=\"english\")\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.592s at 8.508MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.610s at 8.569MB/s\n",
      "n_samples: 7532, n_features: 25631\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, feature_names, target_names = load_dataset(tf_vectorizer, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 Compare three classifiers in sklearn on this multi-class classification task, including at least Na√Øve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform classification and print results\n",
    "def classify_and_print_results(X_train, y_train, X_test, y_test, classifier_name):\n",
    "    if classifier_name == \"Naive Bayes\":\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier_name == \"Logistic Regression\":\n",
    "        clf = LogisticRegression(random_state=0)\n",
    "    elif classifier_name == \"SVM\":\n",
    "        clf = svm.SVC()\n",
    "    elif classifier_name == \"MLP\":\n",
    "        clf = MLPClassifier(random_state=0, max_iter=300)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    precision = precision_score(y_test, y_predict, average='weighted')\n",
    "    recall = recall_score(y_test, y_predict, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predict, average='weighted')\n",
    "    \n",
    "    print(f\"{classifier_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{classifier_name} Precision: {precision:.4f}\")\n",
    "    print(f\"{classifier_name} Recall: {recall:.4f}\")\n",
    "    print(f\"{classifier_name} F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7975\n",
      "Naive Bayes Precision: 0.8143\n",
      "Naive Bayes Recall: 0.7975\n",
      "Naive Bayes F1 Score: 0.7896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.61      0.69       319\n",
      "           1       0.68      0.72      0.70       389\n",
      "           2       0.75      0.72      0.73       394\n",
      "           3       0.64      0.76      0.69       392\n",
      "           4       0.83      0.78      0.80       385\n",
      "           5       0.83      0.77      0.80       395\n",
      "           6       0.85      0.82      0.83       390\n",
      "           7       0.85      0.89      0.87       396\n",
      "           8       0.91      0.94      0.92       398\n",
      "           9       0.91      0.91      0.91       397\n",
      "          10       0.88      0.96      0.92       399\n",
      "          11       0.79      0.94      0.86       396\n",
      "          12       0.79      0.64      0.71       393\n",
      "          13       0.89      0.77      0.83       396\n",
      "          14       0.83      0.91      0.87       394\n",
      "          15       0.63      0.96      0.76       398\n",
      "          16       0.66      0.93      0.77       364\n",
      "          17       0.93      0.91      0.92       376\n",
      "          18       0.96      0.49      0.65       310\n",
      "          19       0.96      0.20      0.34       251\n",
      "\n",
      "    accuracy                           0.80      7532\n",
      "   macro avg       0.82      0.78      0.78      7532\n",
      "weighted avg       0.81      0.80      0.79      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Naive Bayes Accuracy\n",
    "TFNBAcc, TFNBPre, TFNBRe, TFNBF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7949\n",
      "Logistic Regression Precision: 0.7972\n",
      "Logistic Regression Recall: 0.7949\n",
      "Logistic Regression F1 Score: 0.7933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       319\n",
      "           1       0.67      0.74      0.70       389\n",
      "           2       0.73      0.71      0.72       394\n",
      "           3       0.67      0.68      0.67       392\n",
      "           4       0.76      0.78      0.77       385\n",
      "           5       0.79      0.72      0.75       395\n",
      "           6       0.76      0.86      0.81       390\n",
      "           7       0.87      0.85      0.86       396\n",
      "           8       0.88      0.92      0.90       398\n",
      "           9       0.89      0.87      0.88       397\n",
      "          10       0.89      0.93      0.91       399\n",
      "          11       0.94      0.87      0.91       396\n",
      "          12       0.68      0.73      0.70       393\n",
      "          13       0.83      0.79      0.81       396\n",
      "          14       0.88      0.89      0.89       394\n",
      "          15       0.80      0.93      0.86       398\n",
      "          16       0.70      0.86      0.77       364\n",
      "          17       0.95      0.83      0.88       376\n",
      "          18       0.72      0.56      0.63       310\n",
      "          19       0.73      0.49      0.58       251\n",
      "\n",
      "    accuracy                           0.79      7532\n",
      "   macro avg       0.79      0.79      0.79      7532\n",
      "weighted avg       0.80      0.79      0.79      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Logistic Regression Accuracy\n",
    "TFLRAcc, TFLRPre, TFLRRe, TFLRF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7937\n",
      "SVM Precision: 0.8022\n",
      "SVM Recall: 0.7937\n",
      "SVM F1 Score: 0.7937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74       319\n",
      "           1       0.60      0.78      0.68       389\n",
      "           2       0.77      0.68      0.72       394\n",
      "           3       0.67      0.73      0.70       392\n",
      "           4       0.79      0.78      0.78       385\n",
      "           5       0.80      0.71      0.75       395\n",
      "           6       0.76      0.87      0.81       390\n",
      "           7       0.85      0.83      0.84       396\n",
      "           8       0.90      0.90      0.90       398\n",
      "           9       0.88      0.88      0.88       397\n",
      "          10       0.94      0.91      0.92       399\n",
      "          11       0.96      0.85      0.90       396\n",
      "          12       0.62      0.79      0.69       393\n",
      "          13       0.80      0.77      0.79       396\n",
      "          14       0.89      0.87      0.88       394\n",
      "          15       0.81      0.93      0.87       398\n",
      "          16       0.73      0.87      0.79       364\n",
      "          17       0.97      0.79      0.87       376\n",
      "          18       0.74      0.56      0.64       310\n",
      "          19       0.73      0.51      0.60       251\n",
      "\n",
      "    accuracy                           0.79      7532\n",
      "   macro avg       0.80      0.79      0.79      7532\n",
      "weighted avg       0.80      0.79      0.79      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Support Vector Machine Accuracy\n",
    "TFSVMAcc, TFSVMPre, TFSVMRe, TFSVMF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.8415\n",
      "MLP Precision: 0.8444\n",
      "MLP Recall: 0.8415\n",
      "MLP F1 Score: 0.8411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       319\n",
      "           1       0.75      0.80      0.77       389\n",
      "           2       0.77      0.73      0.75       394\n",
      "           3       0.68      0.73      0.70       392\n",
      "           4       0.81      0.84      0.82       385\n",
      "           5       0.86      0.76      0.80       395\n",
      "           6       0.79      0.88      0.83       390\n",
      "           7       0.90      0.90      0.90       396\n",
      "           8       0.96      0.94      0.95       398\n",
      "           9       0.92      0.94      0.93       397\n",
      "          10       0.95      0.96      0.96       399\n",
      "          11       0.94      0.92      0.93       396\n",
      "          12       0.75      0.77      0.76       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.92      0.91      0.92       394\n",
      "          15       0.85      0.92      0.89       398\n",
      "          16       0.74      0.91      0.82       364\n",
      "          17       0.98      0.88      0.93       376\n",
      "          18       0.82      0.60      0.69       310\n",
      "          19       0.72      0.65      0.69       251\n",
      "\n",
      "    accuracy                           0.84      7532\n",
      "   macro avg       0.84      0.84      0.84      7532\n",
      "weighted avg       0.84      0.84      0.84      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Multilayer Perceptron Accuracy\n",
    "TFMLPAcc, TFMLPPre, TFMLPRe, TFMLPF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 Compare three types of features for your classifiers: counts, tf, and tf-idf. Keep the best combination of a classifier and a feature type for the next task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.799s at 7.879MB/s\n",
      "n_samples: 11314, n_features: 130107\n",
      "Vectorize testing done in 1.585s at 8.704MB/s\n",
      "n_samples: 7532, n_features: 130107\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.590s at 8.515MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.616s at 8.537MB/s\n",
      "n_samples: 7532, n_features: 25631\n"
     ]
    }
   ],
   "source": [
    "# The normal TF vectorizer was used in questions 1 and 2, below is the count vectroizer and tf-idf vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\")\n",
    "\n",
    "# Load datasets with different vectorizers\n",
    "X_train_count, X_test_count, y_train_count, y_test_count, feature_names_count, target_names_count = load_dataset(count_vectorizer, verbose=True)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Counts:\n",
      "Naive Bayes Accuracy: 0.7728\n",
      "Naive Bayes Precision: 0.7617\n",
      "Naive Bayes Recall: 0.7728\n",
      "Naive Bayes F1 Score: 0.7511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       319\n",
      "           1       0.67      0.74      0.70       389\n",
      "           2       0.20      0.00      0.01       394\n",
      "           3       0.56      0.77      0.65       392\n",
      "           4       0.84      0.75      0.79       385\n",
      "           5       0.65      0.84      0.73       395\n",
      "           6       0.93      0.65      0.77       390\n",
      "           7       0.87      0.91      0.89       396\n",
      "           8       0.96      0.92      0.94       398\n",
      "           9       0.96      0.87      0.91       397\n",
      "          10       0.93      0.96      0.95       399\n",
      "          11       0.67      0.95      0.78       396\n",
      "          12       0.79      0.66      0.72       393\n",
      "          13       0.87      0.82      0.85       396\n",
      "          14       0.83      0.89      0.86       394\n",
      "          15       0.70      0.96      0.81       398\n",
      "          16       0.69      0.91      0.79       364\n",
      "          17       0.85      0.94      0.89       376\n",
      "          18       0.58      0.63      0.60       310\n",
      "          19       0.89      0.33      0.49       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.76      0.76      0.75      7532\n",
      "weighted avg       0.76      0.77      0.75      7532\n",
      "\n",
      "Naive Bayes TF-IDF:\n",
      "Naive Bayes Accuracy: 0.8238\n",
      "Naive Bayes Precision: 0.8377\n",
      "Naive Bayes Recall: 0.8238\n",
      "Naive Bayes F1 Score: 0.8180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75       319\n",
      "           1       0.73      0.74      0.73       389\n",
      "           2       0.81      0.69      0.75       394\n",
      "           3       0.62      0.80      0.70       392\n",
      "           4       0.86      0.82      0.84       385\n",
      "           5       0.82      0.82      0.82       395\n",
      "           6       0.87      0.83      0.85       390\n",
      "           7       0.90      0.91      0.90       396\n",
      "           8       0.95      0.94      0.95       398\n",
      "           9       0.94      0.93      0.94       397\n",
      "          10       0.90      0.99      0.94       399\n",
      "          11       0.84      0.95      0.89       396\n",
      "          12       0.83      0.67      0.74       393\n",
      "          13       0.92      0.82      0.86       396\n",
      "          14       0.86      0.93      0.89       394\n",
      "          15       0.66      0.96      0.78       398\n",
      "          16       0.69      0.94      0.80       364\n",
      "          17       0.94      0.94      0.94       376\n",
      "          18       0.94      0.55      0.69       310\n",
      "          19       0.93      0.26      0.41       251\n",
      "\n",
      "    accuracy                           0.82      7532\n",
      "   macro avg       0.84      0.81      0.81      7532\n",
      "weighted avg       0.84      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Counts:\")\n",
    "CNBAcc, CNBPre, CBNRe, CNBF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"Naive Bayes\")\n",
    "print(\"Naive Bayes TF-IDF:\")\n",
    "IDFNBAcc, IDFNBPre, IDFNBRe, IDFNBF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Counts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7870\n",
      "Logistic Regression Precision: 0.7888\n",
      "Logistic Regression Recall: 0.7870\n",
      "Logistic Regression F1 Score: 0.7860\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       319\n",
      "           1       0.69      0.74      0.72       389\n",
      "           2       0.71      0.67      0.69       394\n",
      "           3       0.68      0.67      0.68       392\n",
      "           4       0.76      0.80      0.78       385\n",
      "           5       0.81      0.70      0.75       395\n",
      "           6       0.81      0.88      0.85       390\n",
      "           7       0.82      0.84      0.83       396\n",
      "           8       0.90      0.91      0.91       398\n",
      "           9       0.85      0.88      0.86       397\n",
      "          10       0.92      0.92      0.92       399\n",
      "          11       0.90      0.87      0.88       396\n",
      "          12       0.68      0.74      0.70       393\n",
      "          13       0.78      0.74      0.76       396\n",
      "          14       0.90      0.87      0.88       394\n",
      "          15       0.80      0.94      0.87       398\n",
      "          16       0.69      0.84      0.76       364\n",
      "          17       0.94      0.75      0.83       376\n",
      "          18       0.67      0.55      0.60       310\n",
      "          19       0.62      0.59      0.60       251\n",
      "\n",
      "    accuracy                           0.79      7532\n",
      "   macro avg       0.78      0.78      0.78      7532\n",
      "weighted avg       0.79      0.79      0.79      7532\n",
      "\n",
      "Logistic Regression TF-IDF:\n",
      "Logistic Regression Accuracy: 0.8408\n",
      "Logistic Regression Precision: 0.8435\n",
      "Logistic Regression Recall: 0.8408\n",
      "Logistic Regression F1 Score: 0.8391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       319\n",
      "           1       0.72      0.81      0.77       389\n",
      "           2       0.76      0.77      0.76       394\n",
      "           3       0.71      0.74      0.73       392\n",
      "           4       0.81      0.83      0.82       385\n",
      "           5       0.86      0.76      0.81       395\n",
      "           6       0.80      0.88      0.84       390\n",
      "           7       0.91      0.90      0.91       396\n",
      "           8       0.96      0.96      0.96       398\n",
      "           9       0.92      0.94      0.93       397\n",
      "          10       0.95      0.97      0.96       399\n",
      "          11       0.96      0.92      0.94       396\n",
      "          12       0.75      0.77      0.76       393\n",
      "          13       0.89      0.87      0.88       396\n",
      "          14       0.90      0.92      0.91       394\n",
      "          15       0.81      0.94      0.87       398\n",
      "          16       0.73      0.91      0.81       364\n",
      "          17       0.97      0.88      0.92       376\n",
      "          18       0.81      0.59      0.68       310\n",
      "          19       0.79      0.51      0.62       251\n",
      "\n",
      "    accuracy                           0.84      7532\n",
      "   macro avg       0.84      0.83      0.83      7532\n",
      "weighted avg       0.84      0.84      0.84      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Counts:\")\n",
    "CLRAcc, CLRPre, CLRRe, CLRF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"Logistic Regression\")\n",
    "print(\"Logistic Regression TF-IDF:\")\n",
    "IDFLRAcc, IDFLRPre, IDFLRRe, IDFLRF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Counts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.1511\n",
      "SVM Precision: 0.4219\n",
      "SVM Recall: 0.1511\n",
      "SVM F1 Score: 0.1372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.02      0.03       319\n",
      "           1       0.05      0.17      0.08       389\n",
      "           2       0.33      0.02      0.03       394\n",
      "           3       0.63      0.03      0.06       392\n",
      "           4       1.00      0.00      0.01       385\n",
      "           5       0.64      0.05      0.09       395\n",
      "           6       0.09      0.94      0.17       390\n",
      "           7       0.39      0.10      0.15       396\n",
      "           8       0.10      0.25      0.15       398\n",
      "           9       0.52      0.11      0.18       397\n",
      "          10       0.58      0.08      0.14       399\n",
      "          11       0.41      0.16      0.23       396\n",
      "          12       0.21      0.02      0.03       393\n",
      "          13       0.28      0.10      0.15       396\n",
      "          14       0.56      0.05      0.09       394\n",
      "          15       0.42      0.37      0.39       398\n",
      "          16       0.33      0.16      0.21       364\n",
      "          17       0.74      0.26      0.38       376\n",
      "          18       0.73      0.05      0.10       310\n",
      "          19       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.15      7532\n",
      "   macro avg       0.42      0.15      0.13      7532\n",
      "weighted avg       0.42      0.15      0.14      7532\n",
      "\n",
      "SVM TF-IDF:\n",
      "SVM Accuracy: 0.8372\n",
      "SVM Precision: 0.8472\n",
      "SVM Recall: 0.8372\n",
      "SVM F1 Score: 0.8379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78       319\n",
      "           1       0.66      0.84      0.74       389\n",
      "           2       0.81      0.75      0.78       394\n",
      "           3       0.69      0.80      0.74       392\n",
      "           4       0.84      0.82      0.83       385\n",
      "           5       0.90      0.75      0.82       395\n",
      "           6       0.81      0.89      0.85       390\n",
      "           7       0.91      0.89      0.90       396\n",
      "           8       0.97      0.94      0.95       398\n",
      "           9       0.93      0.93      0.93       397\n",
      "          10       0.97      0.95      0.96       399\n",
      "          11       0.97      0.88      0.93       396\n",
      "          12       0.64      0.81      0.72       393\n",
      "          13       0.86      0.86      0.86       396\n",
      "          14       0.92      0.89      0.91       394\n",
      "          15       0.83      0.94      0.88       398\n",
      "          16       0.75      0.90      0.82       364\n",
      "          17       0.99      0.84      0.91       376\n",
      "          18       0.83      0.59      0.69       310\n",
      "          19       0.79      0.59      0.67       251\n",
      "\n",
      "    accuracy                           0.84      7532\n",
      "   macro avg       0.85      0.83      0.83      7532\n",
      "weighted avg       0.85      0.84      0.84      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Counts:\")\n",
    "CSVMAcc, CSVMPre, CSVMRe, CSVMF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"SVM\")\n",
    "print(\"SVM TF-IDF:\")\n",
    "IDFSVMAcc, IDFSVMPre, IDFSVMRe, IDFSVMF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Counts:\n",
      "MLP Accuracy: 0.8285\n",
      "MLP Precision: 0.8326\n",
      "MLP Recall: 0.8285\n",
      "MLP F1 Score: 0.8284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       319\n",
      "           1       0.70      0.80      0.75       389\n",
      "           2       0.73      0.74      0.74       394\n",
      "           3       0.65      0.76      0.70       392\n",
      "           4       0.82      0.83      0.83       385\n",
      "           5       0.88      0.73      0.80       395\n",
      "           6       0.79      0.88      0.83       390\n",
      "           7       0.90      0.90      0.90       396\n",
      "           8       0.97      0.93      0.95       398\n",
      "           9       0.93      0.94      0.93       397\n",
      "          10       0.94      0.97      0.95       399\n",
      "          11       0.92      0.91      0.91       396\n",
      "          12       0.81      0.70      0.75       393\n",
      "          13       0.92      0.77      0.84       396\n",
      "          14       0.90      0.89      0.90       394\n",
      "          15       0.83      0.93      0.88       398\n",
      "          16       0.73      0.88      0.80       364\n",
      "          17       0.95      0.86      0.90       376\n",
      "          18       0.70      0.62      0.66       310\n",
      "          19       0.68      0.61      0.65       251\n",
      "\n",
      "    accuracy                           0.83      7532\n",
      "   macro avg       0.83      0.82      0.82      7532\n",
      "weighted avg       0.83      0.83      0.83      7532\n",
      "\n",
      "MLP TF-IDF:\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Counts:\")\n",
    "CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"MLP\")\n",
    "print(\"MLP TF-IDF:\")\n",
    "IDFMLPAcc, IDFMLPPre, IDFMLPRe, IDFMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.797531  0.794875  0.793680  0.841476\n",
      "IDF  0.823818  0.840813  0.837228  0.858603\n",
      "C    0.772836  0.787042  0.151089  0.828465\n",
      "\n",
      "Precision Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.814310  0.797202  0.802213  0.844420\n",
      "IDF  0.837685  0.843504  0.847194  0.861315\n",
      "C    0.761668  0.788842  0.421916  0.832577\n",
      "\n",
      "Recall Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.797531  0.794875  0.793680  0.841476\n",
      "IDF  0.823818  0.840813  0.837228  0.858603\n",
      "C    0.772836  0.787042  0.151089  0.828465\n",
      "\n",
      "F1 Score Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.789558  0.793313  0.793736  0.841072\n",
      "IDF  0.817977  0.839117  0.837894  0.858213\n",
      "C    0.751113  0.786027  0.137244  0.828368\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'NB': [TFNBAcc, IDFNBAcc, CNBAcc],\n",
    "    'LR': [TFLRAcc, IDFLRAcc, CLRAcc],\n",
    "    'SVM': [TFSVMAcc, IDFSVMAcc, CSVMAcc],\n",
    "    'MLP': [TFMLPAcc, IDFMLPAcc, CMLPAcc]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for Accuracy\n",
    "accuracy_table = pd.DataFrame(data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "# Create a dictionary for Precision\n",
    "precision_data = {\n",
    "    'NB': [TFNBPre, IDFNBPre, CNBPre],\n",
    "    'LR': [TFLRPre, IDFLRPre, CLRPre],\n",
    "    'SVM': [TFSVMPre, IDFSVMPre, CSVMPre],\n",
    "    'MLP': [TFMLPPre, IDFMLPPre, CMLPPre]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for Precision\n",
    "precision_table = pd.DataFrame(precision_data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "# Create a dictionary for Recall\n",
    "recall_data = {\n",
    "    'NB': [TFNBRe, IDFNBRe, CBNRe],\n",
    "    'LR': [TFLRRe, IDFLRRe, CLRRe],\n",
    "    'SVM': [TFSVMRe, IDFSVMRe, CSVMRe],\n",
    "    'MLP': [TFMLPRe, IDFMLPRe, CMLPRe]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for Recall\n",
    "recall_table = pd.DataFrame(recall_data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "# Create a dictionary for F1 Score\n",
    "f1_data = {\n",
    "    'NB': [TFNBF1, IDFNBF1, CNBF1],\n",
    "    'LR': [TFLRF1, IDFLRF1, CLRF1],\n",
    "    'SVM': [TFSVMF1, IDFSVMF1, CSVMF1],\n",
    "    'MLP': [TFMLPF1, IDFMLPF1, CMLPF1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for F1 Score\n",
    "f1_table = pd.DataFrame(f1_data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy Table:\")\n",
    "print(accuracy_table)\n",
    "print(\"\\nPrecision Table:\")\n",
    "print(precision_table)\n",
    "print(\"\\nRecall Table:\")\n",
    "print(recall_table)\n",
    "print(\"\\nF1 Score Table:\")\n",
    "print(f1_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 Look up the documentation of the CountVectorizer function and experiment with different values for the following parameters for your best classifier-feature combination. For each of these parameters compare different values and store the results.\n",
    "a. Lowercasing (true or false)\n",
    "b. stop_words (with or without)\n",
    "c. analyzer (in combination with ngram_range), try out a few values\n",
    "d. max_features, try out a few values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.666s at 8.272MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.631s at 8.459MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.749s at 8.023MB/s\n",
      "n_samples: 11314, n_features: 30935\n",
      "Vectorize testing done in 1.678s at 8.222MB/s\n",
      "n_samples: 7532, n_features: 30935\n",
      "MLP Accuracy: 0.8585\n",
      "MLP Precision: 0.8611\n",
      "MLP Recall: 0.8585\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       319\n",
      "           1       0.73      0.82      0.77       389\n",
      "           2       0.80      0.75      0.77       394\n",
      "           3       0.69      0.79      0.74       392\n",
      "           4       0.85      0.84      0.85       385\n",
      "           5       0.86      0.81      0.84       395\n",
      "           6       0.82      0.92      0.87       390\n",
      "           7       0.92      0.92      0.92       396\n",
      "           8       0.97      0.95      0.96       398\n",
      "           9       0.94      0.94      0.94       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.95      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.92      0.91      0.91       394\n",
      "          15       0.88      0.92      0.90       398\n",
      "          16       0.77      0.92      0.84       364\n",
      "          17       0.98      0.91      0.94       376\n",
      "          18       0.83      0.63      0.72       310\n",
      "          19       0.73      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store results\n",
    "results = []\n",
    "\n",
    "# a. Test Lowercasing\n",
    "for lowercase in [True, False]:\n",
    "    tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, lowercase=lowercase, stop_words=\"english\")\n",
    "    \n",
    "    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "    CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'Lowercasing',\n",
    "        'value': lowercase,\n",
    "        'accuracy': CMLPAcc,\n",
    "        'precision': CMLPPre,\n",
    "        'recall': CMLPRe,\n",
    "        'f1_score': CMLPF1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.735s at 8.064MB/s\n",
      "n_samples: 11314, n_features: 25914\n",
      "Vectorize testing done in 1.860s at 7.418MB/s\n",
      "n_samples: 7532, n_features: 25914\n",
      "MLP Accuracy: 0.8540\n",
      "MLP Precision: 0.8563\n",
      "MLP Recall: 0.8540\n",
      "MLP F1 Score: 0.8534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82       319\n",
      "           1       0.75      0.81      0.78       389\n",
      "           2       0.75      0.75      0.75       394\n",
      "           3       0.69      0.74      0.71       392\n",
      "           4       0.83      0.85      0.84       385\n",
      "           5       0.88      0.77      0.83       395\n",
      "           6       0.81      0.89      0.85       390\n",
      "           7       0.93      0.90      0.92       396\n",
      "           8       0.96      0.96      0.96       398\n",
      "           9       0.93      0.96      0.95       397\n",
      "          10       0.97      0.98      0.97       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.78      0.77      0.78       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.87      0.93      0.90       398\n",
      "          16       0.76      0.92      0.83       364\n",
      "          17       0.98      0.89      0.93       376\n",
      "          18       0.84      0.62      0.71       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.85      0.85      7532\n",
      "weighted avg       0.86      0.85      0.85      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.620s at 8.417MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.584s at 8.710MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Test Stop Words\n",
    "for stop_words in [None, 'english']:\n",
    "    tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words=stop_words)\n",
    "    \n",
    "    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "    CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'Stop Words',\n",
    "        'value': stop_words,\n",
    "        'accuracy': CMLPAcc,\n",
    "        'precision': CMLPPre,\n",
    "        'recall': CMLPRe,\n",
    "        'f1_score': CMLPF1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.708s at 8.144MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.656s at 8.331MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 5.198s at 4.243MB/s\n",
      "n_samples: 11314, n_features: 64194\n",
      "Vectorize testing done in 2.827s at 4.882MB/s\n",
      "n_samples: 7532, n_features: 64194\n",
      "MLP Accuracy: 0.8609\n",
      "MLP Precision: 0.8630\n",
      "MLP Recall: 0.8609\n",
      "MLP F1 Score: 0.8606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83       319\n",
      "           1       0.75      0.82      0.78       389\n",
      "           2       0.78      0.77      0.78       394\n",
      "           3       0.73      0.76      0.74       392\n",
      "           4       0.82      0.84      0.83       385\n",
      "           5       0.87      0.81      0.83       395\n",
      "           6       0.82      0.89      0.86       390\n",
      "           7       0.92      0.90      0.91       396\n",
      "           8       0.95      0.96      0.96       398\n",
      "           9       0.93      0.95      0.94       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.95      0.93      0.94       396\n",
      "          12       0.77      0.80      0.79       393\n",
      "          13       0.88      0.87      0.87       396\n",
      "          14       0.90      0.91      0.91       394\n",
      "          15       0.87      0.92      0.90       398\n",
      "          16       0.80      0.93      0.86       364\n",
      "          17       0.98      0.90      0.94       376\n",
      "          18       0.87      0.67      0.76       310\n",
      "          19       0.76      0.73      0.74       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.86      0.86      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:547: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 3.139s at 7.026MB/s\n",
      "n_samples: 11314, n_features: 28\n",
      "Vectorize testing done in 7.558s at 1.826MB/s\n",
      "n_samples: 7532, n_features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.1600\n",
      "MLP Precision: 0.1547\n",
      "MLP Recall: 0.1600\n",
      "MLP F1 Score: 0.1466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.14      0.17       319\n",
      "           1       0.09      0.03      0.05       389\n",
      "           2       0.12      0.07      0.09       394\n",
      "           3       0.11      0.15      0.12       392\n",
      "           4       0.09      0.03      0.05       385\n",
      "           5       0.15      0.14      0.15       395\n",
      "           6       0.35      0.56      0.43       390\n",
      "           7       0.13      0.04      0.06       396\n",
      "           8       0.41      0.43      0.42       398\n",
      "           9       0.08      0.24      0.13       397\n",
      "          10       0.15      0.24      0.18       399\n",
      "          11       0.14      0.14      0.14       396\n",
      "          12       0.05      0.01      0.02       393\n",
      "          13       0.14      0.14      0.14       396\n",
      "          14       0.14      0.14      0.14       394\n",
      "          15       0.13      0.27      0.18       398\n",
      "          16       0.07      0.07      0.07       364\n",
      "          17       0.23      0.13      0.16       376\n",
      "          18       0.27      0.14      0.19       310\n",
      "          19       0.06      0.02      0.02       251\n",
      "\n",
      "    accuracy                           0.16      7532\n",
      "   macro avg       0.15      0.16      0.14      7532\n",
      "weighted avg       0.15      0.16      0.15      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:547: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 10.547s at 2.091MB/s\n",
      "n_samples: 11314, n_features: 4428\n",
      "Vectorize testing done in 17.298s at 0.798MB/s\n",
      "n_samples: 7532, n_features: 4428\n",
      "MLP Accuracy: 0.6378\n",
      "MLP Precision: 0.6427\n",
      "MLP Recall: 0.6378\n",
      "MLP F1 Score: 0.6392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       319\n",
      "           1       0.48      0.51      0.50       389\n",
      "           2       0.53      0.54      0.53       394\n",
      "           3       0.57      0.50      0.53       392\n",
      "           4       0.53      0.59      0.56       385\n",
      "           5       0.80      0.78      0.79       395\n",
      "           6       0.71      0.74      0.72       390\n",
      "           7       0.57      0.56      0.57       396\n",
      "           8       0.81      0.79      0.80       398\n",
      "           9       0.71      0.63      0.67       397\n",
      "          10       0.78      0.76      0.77       399\n",
      "          11       0.77      0.79      0.78       396\n",
      "          12       0.41      0.48      0.44       393\n",
      "          13       0.47      0.44      0.45       396\n",
      "          14       0.62      0.71      0.66       394\n",
      "          15       0.79      0.82      0.81       398\n",
      "          16       0.70      0.67      0.68       364\n",
      "          17       0.85      0.74      0.79       376\n",
      "          18       0.60      0.54      0.57       310\n",
      "          19       0.41      0.46      0.44       251\n",
      "\n",
      "    accuracy                           0.64      7532\n",
      "   macro avg       0.64      0.63      0.63      7532\n",
      "weighted avg       0.64      0.64      0.64      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Test Analyzer and Ngram Range\n",
    "for analyzer in ['word', 'char']:\n",
    "    for ngram_range in [(1, 1), (1, 2)]:\n",
    "        tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, analyzer=analyzer, ngram_range=ngram_range, min_df=5, stop_words=\"english\")\n",
    "        \n",
    "        X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "        CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "        \n",
    "        results.append({\n",
    "            'test': 'Analyzer and Ngram Range',\n",
    "            'analyzer': analyzer,\n",
    "            'ngram_range': ngram_range,\n",
    "            'accuracy': CMLPAcc,\n",
    "            'precision': CMLPPre,\n",
    "            'recall': CMLPRe,\n",
    "            'f1_score': CMLPF1\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.680s at 8.229MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.682s at 8.203MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.776s at 7.944MB/s\n",
      "n_samples: 11314, n_features: 1000\n",
      "Vectorize testing done in 1.693s at 8.149MB/s\n",
      "n_samples: 7532, n_features: 1000\n",
      "MLP Accuracy: 0.6470\n",
      "MLP Precision: 0.6519\n",
      "MLP Recall: 0.6470\n",
      "MLP F1 Score: 0.6483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61       319\n",
      "           1       0.59      0.59      0.59       389\n",
      "           2       0.58      0.57      0.58       394\n",
      "           3       0.49      0.49      0.49       392\n",
      "           4       0.59      0.64      0.62       385\n",
      "           5       0.65      0.64      0.64       395\n",
      "           6       0.73      0.75      0.74       390\n",
      "           7       0.64      0.69      0.67       396\n",
      "           8       0.74      0.77      0.75       398\n",
      "           9       0.73      0.69      0.71       397\n",
      "          10       0.81      0.84      0.82       399\n",
      "          11       0.85      0.78      0.81       396\n",
      "          12       0.42      0.44      0.43       393\n",
      "          13       0.58      0.57      0.57       396\n",
      "          14       0.77      0.76      0.76       394\n",
      "          15       0.78      0.74      0.76       398\n",
      "          16       0.60      0.68      0.64       364\n",
      "          17       0.87      0.67      0.75       376\n",
      "          18       0.51      0.46      0.48       310\n",
      "          19       0.38      0.43      0.40       251\n",
      "\n",
      "    accuracy                           0.65      7532\n",
      "   macro avg       0.64      0.64      0.64      7532\n",
      "weighted avg       0.65      0.65      0.65      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.776s at 7.944MB/s\n",
      "n_samples: 11314, n_features: 5000\n",
      "Vectorize testing done in 1.640s at 8.413MB/s\n",
      "n_samples: 7532, n_features: 5000\n",
      "MLP Accuracy: 0.8099\n",
      "MLP Precision: 0.8130\n",
      "MLP Recall: 0.8099\n",
      "MLP F1 Score: 0.8097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       319\n",
      "           1       0.69      0.76      0.72       389\n",
      "           2       0.76      0.71      0.73       394\n",
      "           3       0.63      0.71      0.66       392\n",
      "           4       0.81      0.80      0.81       385\n",
      "           5       0.83      0.75      0.79       395\n",
      "           6       0.80      0.87      0.83       390\n",
      "           7       0.85      0.87      0.86       396\n",
      "           8       0.92      0.92      0.92       398\n",
      "           9       0.93      0.91      0.92       397\n",
      "          10       0.95      0.97      0.96       399\n",
      "          11       0.96      0.91      0.93       396\n",
      "          12       0.67      0.69      0.68       393\n",
      "          13       0.83      0.81      0.82       396\n",
      "          14       0.87      0.90      0.88       394\n",
      "          15       0.83      0.89      0.86       398\n",
      "          16       0.72      0.87      0.79       364\n",
      "          17       0.98      0.84      0.90       376\n",
      "          18       0.74      0.55      0.63       310\n",
      "          19       0.61      0.59      0.60       251\n",
      "\n",
      "    accuracy                           0.81      7532\n",
      "   macro avg       0.81      0.80      0.80      7532\n",
      "weighted avg       0.81      0.81      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Test Max Features\n",
    "for max_features in [None, 1000, 5000]:\n",
    "    tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\", max_features=max_features)\n",
    "    \n",
    "    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "    CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'Max Features',\n",
    "        'value': max_features,\n",
    "        'accuracy': CMLPAcc,\n",
    "        'precision': CMLPPre,\n",
    "        'recall': CMLPRe,\n",
    "        'f1_score': CMLPF1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        test    value  accuracy  precision    recall  \\\n",
      "0                Lowercasing     True  0.858603   0.861315  0.858603   \n",
      "1                Lowercasing    False  0.858471   0.861084  0.858471   \n",
      "2                 Stop Words     None  0.853956   0.856261  0.853956   \n",
      "3                 Stop Words  english  0.858603   0.861315  0.858603   \n",
      "4   Analyzer and Ngram Range      NaN  0.858603   0.861315  0.858603   \n",
      "5   Analyzer and Ngram Range      NaN  0.860860   0.863019  0.860860   \n",
      "6   Analyzer and Ngram Range      NaN  0.159984   0.154684  0.159984   \n",
      "7   Analyzer and Ngram Range      NaN  0.637812   0.642718  0.637812   \n",
      "8               Max Features     None  0.858603   0.861315  0.858603   \n",
      "9               Max Features     1000  0.646973   0.651936  0.646973   \n",
      "10              Max Features     5000  0.809878   0.813018  0.809878   \n",
      "\n",
      "    f1_score analyzer ngram_range  \n",
      "0   0.858213      NaN         NaN  \n",
      "1   0.858194      NaN         NaN  \n",
      "2   0.853414      NaN         NaN  \n",
      "3   0.858213      NaN         NaN  \n",
      "4   0.858213     word      (1, 1)  \n",
      "5   0.860604     word      (1, 2)  \n",
      "6   0.146551     char      (1, 1)  \n",
      "7   0.639190     char      (1, 2)  \n",
      "8   0.858213      NaN         NaN  \n",
      "9   0.648300      NaN         NaN  \n",
      "10  0.809660      NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 5.232s at 4.215MB/s\n",
      "n_samples: 11314, n_features: 64194\n",
      "Vectorize testing done in 2.784s at 4.957MB/s\n",
      "n_samples: 7532, n_features: 64194\n",
      "MLP Accuracy: 0.8609\n",
      "MLP Precision: 0.8630\n",
      "MLP Recall: 0.8609\n",
      "MLP F1 Score: 0.8606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83       319\n",
      "           1       0.75      0.82      0.78       389\n",
      "           2       0.78      0.77      0.78       394\n",
      "           3       0.73      0.76      0.74       392\n",
      "           4       0.82      0.84      0.83       385\n",
      "           5       0.87      0.81      0.83       395\n",
      "           6       0.82      0.89      0.86       390\n",
      "           7       0.92      0.90      0.91       396\n",
      "           8       0.95      0.96      0.96       398\n",
      "           9       0.93      0.95      0.94       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.95      0.93      0.94       396\n",
      "          12       0.77      0.80      0.79       393\n",
      "          13       0.88      0.87      0.87       396\n",
      "          14       0.90      0.91      0.91       394\n",
      "          15       0.87      0.92      0.90       398\n",
      "          16       0.80      0.93      0.86       364\n",
      "          17       0.98      0.90      0.94       376\n",
      "          18       0.87      0.67      0.76       310\n",
      "          19       0.76      0.73      0.74       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.86      0.86      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimal settings test\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True, \n",
    "    max_df=0.5, \n",
    "    min_df=5, \n",
    "    stop_words=\"english\", \n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True  \n",
    ")\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8608603292618162 0.8630192877572318 0.8608603292618162 0.8606036212727489\n"
     ]
    }
   ],
   "source": [
    "print(CMLPAcc, CMLPPre, CMLPRe, CMLPF1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
