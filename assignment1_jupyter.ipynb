{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Text Mining Emma Vonk, Julius Ruijgrok\n",
    "## Question 1 The tutorial classifies between only four categories of the 20newsgroups data set. Change your script so that it addresses all 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1 of text mining\n",
    "\n",
    "# code from https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def load_dataset(vectorizer, verbose=False, remove=()):\n",
    "    \"\"\"Load and vectorize the 20 newsgroups dataset using the specified vectorizer.\"\"\"\n",
    "    \n",
    "    data_train = fetch_20newsgroups(\n",
    "        subset=\"train\",\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "\n",
    "    data_test = fetch_20newsgroups(\n",
    "        subset=\"test\",\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "\n",
    "    # Order of labels in `target_names` can be different from `categories`\n",
    "    target_names = data_train.target_names\n",
    "\n",
    "    # Split target in a training set and a test set\n",
    "    y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "    # Extracting features from the training data using the specified vectorizer\n",
    "    t0 = time()\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "    duration_train = time() - t0\n",
    "\n",
    "    # Extracting features from the test data using the same vectorizer\n",
    "    t0 = time()\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    duration_test = time() - t0\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    if verbose:\n",
    "        # Compute size of loaded data\n",
    "        data_train_size_mb = size_mb(data_train.data)\n",
    "        data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "        print(f\"{len(data_train.data)} documents - {data_train_size_mb:.2f}MB (training set)\")\n",
    "        print(f\"{len(data_test.data)} documents - {data_test_size_mb:.2f}MB (test set)\")\n",
    "        print(f\"{len(target_names)} categories\")\n",
    "        print(f\"Vectorize training done in {duration_train:.3f}s at {data_train_size_mb / duration_train:.3f}MB/s\")\n",
    "        print(f\"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}\")\n",
    "        print(f\"Vectorize testing done in {duration_test:.3f}s at {data_test_size_mb / duration_test:.3f}MB/s\")\n",
    "        print(f\"n_samples: {X_test.shape[0]}, n_features: {X_test.shape[1]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, feature_names, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different vectorizers to be used later\n",
    "count_vectorizer = CountVectorizer()\n",
    "tf_vectorizer = TfidfVectorizer(sublinear_tf=False, max_df=0.5, min_df=5, stop_words=\"english\")\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.325s at 9.486MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.337s at 10.320MB/s\n",
      "n_samples: 7532, n_features: 25631\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, feature_names, target_names = load_dataset(tf_vectorizer, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 Compare three classifiers in sklearn on this multi-class classification task, including at least Na√Øve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform classification and print results\n",
    "def classify_and_print_results(X_train, y_train, X_test, y_test, classifier_name):\n",
    "    if classifier_name == \"Naive Bayes\":\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier_name == \"Logistic Regression\":\n",
    "        clf = LogisticRegression(random_state=0)\n",
    "    elif classifier_name == \"SVM\":\n",
    "        clf = svm.SVC()\n",
    "    elif classifier_name == \"MLP\":\n",
    "        clf = MLPClassifier(random_state=0, max_iter=300)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    precision = precision_score(y_test, y_predict, average='weighted')\n",
    "    recall = recall_score(y_test, y_predict, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predict, average='weighted')\n",
    "    \n",
    "    print(f\"{classifier_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{classifier_name} Precision: {precision:.4f}\")\n",
    "    print(f\"{classifier_name} Recall: {recall:.4f}\")\n",
    "    print(f\"{classifier_name} F1 Score: {f1:.4f}\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8173\n",
      "Naive Bayes Precision: 0.8302\n",
      "Naive Bayes Recall: 0.8173\n",
      "Naive Bayes F1 Score: 0.8118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       319\n",
      "           1       0.72      0.74      0.73       389\n",
      "           2       0.77      0.72      0.74       394\n",
      "           3       0.64      0.78      0.70       392\n",
      "           4       0.85      0.81      0.83       385\n",
      "           5       0.85      0.79      0.82       395\n",
      "           6       0.84      0.82      0.83       390\n",
      "           7       0.88      0.90      0.89       396\n",
      "           8       0.93      0.94      0.94       398\n",
      "           9       0.92      0.92      0.92       397\n",
      "          10       0.89      0.98      0.93       399\n",
      "          11       0.84      0.95      0.89       396\n",
      "          12       0.82      0.66      0.73       393\n",
      "          13       0.92      0.80      0.86       396\n",
      "          14       0.84      0.93      0.88       394\n",
      "          15       0.66      0.95      0.78       398\n",
      "          16       0.68      0.93      0.78       364\n",
      "          17       0.94      0.93      0.94       376\n",
      "          18       0.93      0.53      0.68       310\n",
      "          19       0.92      0.28      0.43       251\n",
      "\n",
      "    accuracy                           0.82      7532\n",
      "   macro avg       0.83      0.80      0.80      7532\n",
      "weighted avg       0.83      0.82      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Naive Bayes Accuracy\n",
    "TFNBAcc, TFNBPre, TFNBRe, TFNBF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8278\n",
      "Logistic Regression Precision: 0.8305\n",
      "Logistic Regression Recall: 0.8278\n",
      "Logistic Regression F1 Score: 0.8262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75       319\n",
      "           1       0.70      0.80      0.75       389\n",
      "           2       0.75      0.75      0.75       394\n",
      "           3       0.70      0.73      0.72       392\n",
      "           4       0.80      0.82      0.81       385\n",
      "           5       0.84      0.74      0.79       395\n",
      "           6       0.78      0.86      0.82       390\n",
      "           7       0.89      0.88      0.89       396\n",
      "           8       0.94      0.94      0.94       398\n",
      "           9       0.90      0.92      0.91       397\n",
      "          10       0.94      0.96      0.95       399\n",
      "          11       0.95      0.90      0.92       396\n",
      "          12       0.72      0.77      0.74       393\n",
      "          13       0.88      0.85      0.87       396\n",
      "          14       0.89      0.91      0.90       394\n",
      "          15       0.81      0.93      0.87       398\n",
      "          16       0.73      0.90      0.81       364\n",
      "          17       0.97      0.89      0.93       376\n",
      "          18       0.82      0.60      0.70       310\n",
      "          19       0.75      0.49      0.59       251\n",
      "\n",
      "    accuracy                           0.83      7532\n",
      "   macro avg       0.83      0.82      0.82      7532\n",
      "weighted avg       0.83      0.83      0.83      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Logistic Regression Accuracy\n",
    "TFLRAcc, TFLRPre, TFLRRe, TFLRF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8210\n",
      "SVM Precision: 0.8321\n",
      "SVM Recall: 0.8210\n",
      "SVM F1 Score: 0.8216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76       319\n",
      "           1       0.63      0.83      0.72       389\n",
      "           2       0.79      0.72      0.75       394\n",
      "           3       0.69      0.78      0.73       392\n",
      "           4       0.83      0.82      0.83       385\n",
      "           5       0.84      0.72      0.77       395\n",
      "           6       0.76      0.89      0.82       390\n",
      "           7       0.88      0.87      0.87       396\n",
      "           8       0.97      0.92      0.94       398\n",
      "           9       0.92      0.92      0.92       397\n",
      "          10       0.96      0.94      0.95       399\n",
      "          11       0.97      0.86      0.91       396\n",
      "          12       0.63      0.82      0.71       393\n",
      "          13       0.86      0.84      0.85       396\n",
      "          14       0.91      0.87      0.89       394\n",
      "          15       0.81      0.93      0.86       398\n",
      "          16       0.75      0.88      0.81       364\n",
      "          17       0.98      0.80      0.88       376\n",
      "          18       0.80      0.59      0.68       310\n",
      "          19       0.80      0.55      0.65       251\n",
      "\n",
      "    accuracy                           0.82      7532\n",
      "   macro avg       0.83      0.81      0.82      7532\n",
      "weighted avg       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Support Vector Machine Accuracy\n",
    "TFSVMAcc, TFSVMPre, TFSVMRe, TFSVMF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.8475\n",
      "MLP Precision: 0.8503\n",
      "MLP Recall: 0.8475\n",
      "MLP F1 Score: 0.8472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81       319\n",
      "           1       0.73      0.82      0.77       389\n",
      "           2       0.77      0.72      0.74       394\n",
      "           3       0.69      0.76      0.72       392\n",
      "           4       0.80      0.85      0.83       385\n",
      "           5       0.87      0.77      0.82       395\n",
      "           6       0.79      0.89      0.84       390\n",
      "           7       0.92      0.89      0.91       396\n",
      "           8       0.95      0.95      0.95       398\n",
      "           9       0.93      0.95      0.94       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.94      0.92      0.93       396\n",
      "          12       0.78      0.76      0.77       393\n",
      "          13       0.91      0.86      0.89       396\n",
      "          14       0.92      0.91      0.91       394\n",
      "          15       0.85      0.92      0.88       398\n",
      "          16       0.76      0.89      0.82       364\n",
      "          17       0.98      0.91      0.94       376\n",
      "          18       0.82      0.63      0.71       310\n",
      "          19       0.72      0.67      0.69       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.84      0.84      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-vectorizer Multilayer Perceptron Accuracy\n",
    "TFMLPAcc, TFMLPPre, TFMLPRe, TFMLPF1 = classify_and_print_results(X_train, y_train, X_test, y_test, \"MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 Compare three types of features for your classifiers: counts, tf, and tf-idf. Keep the best combination of a classifier and a feature type for the next task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.658s at 8.297MB/s\n",
      "n_samples: 11314, n_features: 130107\n",
      "Vectorize testing done in 1.329s at 10.383MB/s\n",
      "n_samples: 7532, n_features: 130107\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.318s at 9.514MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.426s at 9.677MB/s\n",
      "n_samples: 7532, n_features: 25631\n"
     ]
    }
   ],
   "source": [
    "# The normal TF vectorizer was used in questions 1 and 2, below is the count vectroizer and tf-idf vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\")\n",
    "\n",
    "# Load datasets with different vectorizers\n",
    "X_train_count, X_test_count, y_train_count, y_test_count, feature_names_count, target_names_count = load_dataset(count_vectorizer, verbose=True)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Counts:\n",
      "Naive Bayes Accuracy: 0.7728\n",
      "Naive Bayes Precision: 0.7617\n",
      "Naive Bayes Recall: 0.7728\n",
      "Naive Bayes F1 Score: 0.7511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       319\n",
      "           1       0.67      0.74      0.70       389\n",
      "           2       0.20      0.00      0.01       394\n",
      "           3       0.56      0.77      0.65       392\n",
      "           4       0.84      0.75      0.79       385\n",
      "           5       0.65      0.84      0.73       395\n",
      "           6       0.93      0.65      0.77       390\n",
      "           7       0.87      0.91      0.89       396\n",
      "           8       0.96      0.92      0.94       398\n",
      "           9       0.96      0.87      0.91       397\n",
      "          10       0.93      0.96      0.95       399\n",
      "          11       0.67      0.95      0.78       396\n",
      "          12       0.79      0.66      0.72       393\n",
      "          13       0.87      0.82      0.85       396\n",
      "          14       0.83      0.89      0.86       394\n",
      "          15       0.70      0.96      0.81       398\n",
      "          16       0.69      0.91      0.79       364\n",
      "          17       0.85      0.94      0.89       376\n",
      "          18       0.58      0.63      0.60       310\n",
      "          19       0.89      0.33      0.49       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.76      0.76      0.75      7532\n",
      "weighted avg       0.76      0.77      0.75      7532\n",
      "\n",
      "Naive Bayes TF-IDF:\n",
      "Naive Bayes Accuracy: 0.8238\n",
      "Naive Bayes Precision: 0.8377\n",
      "Naive Bayes Recall: 0.8238\n",
      "Naive Bayes F1 Score: 0.8180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75       319\n",
      "           1       0.73      0.74      0.73       389\n",
      "           2       0.81      0.69      0.75       394\n",
      "           3       0.62      0.80      0.70       392\n",
      "           4       0.86      0.82      0.84       385\n",
      "           5       0.82      0.82      0.82       395\n",
      "           6       0.87      0.83      0.85       390\n",
      "           7       0.90      0.91      0.90       396\n",
      "           8       0.95      0.94      0.95       398\n",
      "           9       0.94      0.93      0.94       397\n",
      "          10       0.90      0.99      0.94       399\n",
      "          11       0.84      0.95      0.89       396\n",
      "          12       0.83      0.67      0.74       393\n",
      "          13       0.92      0.82      0.86       396\n",
      "          14       0.86      0.93      0.89       394\n",
      "          15       0.66      0.96      0.78       398\n",
      "          16       0.69      0.94      0.80       364\n",
      "          17       0.94      0.94      0.94       376\n",
      "          18       0.94      0.55      0.69       310\n",
      "          19       0.93      0.26      0.41       251\n",
      "\n",
      "    accuracy                           0.82      7532\n",
      "   macro avg       0.84      0.81      0.81      7532\n",
      "weighted avg       0.84      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Counts:\")\n",
    "CNBAcc, CNBPre, CBNRe, CNBF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"Naive Bayes\")\n",
    "print(\"Naive Bayes TF-IDF:\")\n",
    "IDFNBAcc, IDFNBPre, IDFNBRe, IDFNBF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Counts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7894\n",
      "Logistic Regression Precision: 0.7918\n",
      "Logistic Regression Recall: 0.7894\n",
      "Logistic Regression F1 Score: 0.7887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73       319\n",
      "           1       0.66      0.75      0.71       389\n",
      "           2       0.72      0.67      0.69       394\n",
      "           3       0.67      0.68      0.68       392\n",
      "           4       0.76      0.81      0.78       385\n",
      "           5       0.81      0.69      0.75       395\n",
      "           6       0.81      0.88      0.85       390\n",
      "           7       0.81      0.84      0.83       396\n",
      "           8       0.91      0.92      0.91       398\n",
      "           9       0.84      0.88      0.86       397\n",
      "          10       0.92      0.91      0.92       399\n",
      "          11       0.89      0.87      0.88       396\n",
      "          12       0.69      0.73      0.71       393\n",
      "          13       0.82      0.71      0.76       396\n",
      "          14       0.90      0.89      0.89       394\n",
      "          15       0.84      0.92      0.88       398\n",
      "          16       0.70      0.84      0.76       364\n",
      "          17       0.93      0.78      0.85       376\n",
      "          18       0.68      0.55      0.61       310\n",
      "          19       0.61      0.61      0.61       251\n",
      "\n",
      "    accuracy                           0.79      7532\n",
      "   macro avg       0.79      0.78      0.78      7532\n",
      "weighted avg       0.79      0.79      0.79      7532\n",
      "\n",
      "Logistic Regression TF-IDF:\n",
      "Logistic Regression Accuracy: 0.8408\n",
      "Logistic Regression Precision: 0.8435\n",
      "Logistic Regression Recall: 0.8408\n",
      "Logistic Regression F1 Score: 0.8391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       319\n",
      "           1       0.72      0.81      0.77       389\n",
      "           2       0.76      0.77      0.76       394\n",
      "           3       0.71      0.74      0.73       392\n",
      "           4       0.81      0.83      0.82       385\n",
      "           5       0.86      0.76      0.81       395\n",
      "           6       0.80      0.88      0.84       390\n",
      "           7       0.91      0.90      0.91       396\n",
      "           8       0.96      0.96      0.96       398\n",
      "           9       0.92      0.94      0.93       397\n",
      "          10       0.95      0.97      0.96       399\n",
      "          11       0.96      0.92      0.94       396\n",
      "          12       0.75      0.77      0.76       393\n",
      "          13       0.89      0.87      0.88       396\n",
      "          14       0.90      0.92      0.91       394\n",
      "          15       0.81      0.94      0.87       398\n",
      "          16       0.73      0.91      0.81       364\n",
      "          17       0.97      0.88      0.92       376\n",
      "          18       0.81      0.59      0.68       310\n",
      "          19       0.79      0.51      0.62       251\n",
      "\n",
      "    accuracy                           0.84      7532\n",
      "   macro avg       0.84      0.83      0.83      7532\n",
      "weighted avg       0.84      0.84      0.84      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Counts:\")\n",
    "CLRAcc, CLRPre, CLRRe, CLRF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"Logistic Regression\")\n",
    "print(\"Logistic Regression TF-IDF:\")\n",
    "IDFLRAcc, IDFLRPre, IDFLRRe, IDFLRF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Counts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.1511\n",
      "SVM Precision: 0.4219\n",
      "SVM Recall: 0.1511\n",
      "SVM F1 Score: 0.1372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.02      0.03       319\n",
      "           1       0.05      0.17      0.08       389\n",
      "           2       0.33      0.02      0.03       394\n",
      "           3       0.63      0.03      0.06       392\n",
      "           4       1.00      0.00      0.01       385\n",
      "           5       0.64      0.05      0.09       395\n",
      "           6       0.09      0.94      0.17       390\n",
      "           7       0.39      0.10      0.15       396\n",
      "           8       0.10      0.25      0.15       398\n",
      "           9       0.52      0.11      0.18       397\n",
      "          10       0.58      0.08      0.14       399\n",
      "          11       0.41      0.16      0.23       396\n",
      "          12       0.21      0.02      0.03       393\n",
      "          13       0.28      0.10      0.15       396\n",
      "          14       0.56      0.05      0.09       394\n",
      "          15       0.42      0.37      0.39       398\n",
      "          16       0.33      0.16      0.21       364\n",
      "          17       0.74      0.26      0.38       376\n",
      "          18       0.73      0.05      0.10       310\n",
      "          19       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.15      7532\n",
      "   macro avg       0.42      0.15      0.13      7532\n",
      "weighted avg       0.42      0.15      0.14      7532\n",
      "\n",
      "SVM TF-IDF:\n",
      "SVM Accuracy: 0.8372\n",
      "SVM Precision: 0.8472\n",
      "SVM Recall: 0.8372\n",
      "SVM F1 Score: 0.8379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78       319\n",
      "           1       0.66      0.84      0.74       389\n",
      "           2       0.81      0.75      0.78       394\n",
      "           3       0.69      0.80      0.74       392\n",
      "           4       0.84      0.82      0.83       385\n",
      "           5       0.90      0.75      0.82       395\n",
      "           6       0.81      0.89      0.85       390\n",
      "           7       0.91      0.89      0.90       396\n",
      "           8       0.97      0.94      0.95       398\n",
      "           9       0.93      0.93      0.93       397\n",
      "          10       0.97      0.95      0.96       399\n",
      "          11       0.97      0.88      0.93       396\n",
      "          12       0.64      0.81      0.72       393\n",
      "          13       0.86      0.86      0.86       396\n",
      "          14       0.92      0.89      0.91       394\n",
      "          15       0.83      0.94      0.88       398\n",
      "          16       0.75      0.90      0.82       364\n",
      "          17       0.99      0.84      0.91       376\n",
      "          18       0.83      0.59      0.69       310\n",
      "          19       0.79      0.59      0.67       251\n",
      "\n",
      "    accuracy                           0.84      7532\n",
      "   macro avg       0.85      0.83      0.83      7532\n",
      "weighted avg       0.85      0.84      0.84      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Counts:\")\n",
    "CSVMAcc, CSVMPre, CSVMRe, CSVMF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"SVM\")\n",
    "print(\"SVM TF-IDF:\")\n",
    "IDFSVMAcc, IDFSVMPre, IDFSVMRe, IDFSVMF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Counts:\n",
      "MLP Accuracy: 0.8285\n",
      "MLP Precision: 0.8326\n",
      "MLP Recall: 0.8285\n",
      "MLP F1 Score: 0.8284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       319\n",
      "           1       0.70      0.80      0.75       389\n",
      "           2       0.73      0.74      0.74       394\n",
      "           3       0.65      0.76      0.70       392\n",
      "           4       0.82      0.83      0.83       385\n",
      "           5       0.88      0.73      0.80       395\n",
      "           6       0.79      0.88      0.83       390\n",
      "           7       0.90      0.90      0.90       396\n",
      "           8       0.97      0.93      0.95       398\n",
      "           9       0.93      0.94      0.93       397\n",
      "          10       0.94      0.97      0.95       399\n",
      "          11       0.92      0.91      0.91       396\n",
      "          12       0.81      0.70      0.75       393\n",
      "          13       0.92      0.77      0.84       396\n",
      "          14       0.90      0.89      0.90       394\n",
      "          15       0.83      0.93      0.88       398\n",
      "          16       0.73      0.88      0.80       364\n",
      "          17       0.95      0.86      0.90       376\n",
      "          18       0.70      0.62      0.66       310\n",
      "          19       0.68      0.61      0.65       251\n",
      "\n",
      "    accuracy                           0.83      7532\n",
      "   macro avg       0.83      0.82      0.82      7532\n",
      "weighted avg       0.83      0.83      0.83      7532\n",
      "\n",
      "MLP TF-IDF:\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP Counts:\")\n",
    "CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_count, y_train_count, X_test_count, y_test_count, \"MLP\")\n",
    "print(\"MLP TF-IDF:\")\n",
    "IDFMLPAcc, IDFMLPPre, IDFMLPRe, IDFMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.817313  0.827801  0.821030  0.847451\n",
      "IDF  0.823818  0.840813  0.837228  0.858603\n",
      "C    0.772836  0.789432  0.151089  0.828465\n",
      "\n",
      "Precision Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.830226  0.830501  0.832077  0.850299\n",
      "IDF  0.837685  0.843504  0.847194  0.861315\n",
      "C    0.761668  0.791764  0.421916  0.832577\n",
      "\n",
      "Recall Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.817313  0.827801  0.821030  0.847451\n",
      "IDF  0.823818  0.840813  0.837228  0.858603\n",
      "C    0.772836  0.789432  0.151089  0.828465\n",
      "\n",
      "F1 Score Table:\n",
      "           NB        LR       SVM       MLP\n",
      "TF   0.811799  0.826237  0.821644  0.847185\n",
      "IDF  0.817977  0.839117  0.837894  0.858213\n",
      "C    0.751113  0.788702  0.137244  0.828368\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'NB': [TFNBAcc, IDFNBAcc, CNBAcc],\n",
    "    'LR': [TFLRAcc, IDFLRAcc, CLRAcc],\n",
    "    'SVM': [TFSVMAcc, IDFSVMAcc, CSVMAcc],\n",
    "    'MLP': [TFMLPAcc, IDFMLPAcc, CMLPAcc]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for Accuracy\n",
    "accuracy_table = pd.DataFrame(data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "# Create a dictionary for Precision\n",
    "precision_data = {\n",
    "    'NB': [TFNBPre, IDFNBPre, CNBPre],\n",
    "    'LR': [TFLRPre, IDFLRPre, CLRPre],\n",
    "    'SVM': [TFSVMPre, IDFSVMPre, CSVMPre],\n",
    "    'MLP': [TFMLPPre, IDFMLPPre, CMLPPre]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for Precision\n",
    "precision_table = pd.DataFrame(precision_data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "# Create a dictionary for Recall\n",
    "recall_data = {\n",
    "    'NB': [TFNBRe, IDFNBRe, CBNRe],\n",
    "    'LR': [TFLRRe, IDFLRRe, CLRRe],\n",
    "    'SVM': [TFSVMRe, IDFSVMRe, CSVMRe],\n",
    "    'MLP': [TFMLPRe, IDFMLPRe, CMLPRe]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for Recall\n",
    "recall_table = pd.DataFrame(recall_data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "# Create a dictionary for F1 Score\n",
    "f1_data = {\n",
    "    'NB': [TFNBF1, IDFNBF1, CNBF1],\n",
    "    'LR': [TFLRF1, IDFLRF1, CLRF1],\n",
    "    'SVM': [TFSVMF1, IDFSVMF1, CSVMF1],\n",
    "    'MLP': [TFMLPF1, IDFMLPF1, CMLPF1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for F1 Score\n",
    "f1_table = pd.DataFrame(f1_data, index=['TF', 'IDF', 'C'])\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Accuracy Table:\")\n",
    "print(accuracy_table)\n",
    "print(\"\\nPrecision Table:\")\n",
    "print(precision_table)\n",
    "print(\"\\nRecall Table:\")\n",
    "print(recall_table)\n",
    "print(\"\\nF1 Score Table:\")\n",
    "print(f1_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 Look up the documentation of the CountVectorizer function and experiment with different values for the following parameters for your best classifier-feature combination. For each of these parameters compare different values and store the results.\n",
    "a. Lowercasing (true or false)\n",
    "b. stop_words (with or without)\n",
    "c. analyzer (in combination with ngram_range), try out a few values\n",
    "d. max_features, try out a few values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.568s at 8.588MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.293s at 10.672MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.211s at 9.976MB/s\n",
      "n_samples: 11314, n_features: 30935\n",
      "Vectorize testing done in 1.269s at 10.878MB/s\n",
      "n_samples: 7532, n_features: 30935\n",
      "MLP Accuracy: 0.8585\n",
      "MLP Precision: 0.8611\n",
      "MLP Recall: 0.8585\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       319\n",
      "           1       0.73      0.82      0.77       389\n",
      "           2       0.80      0.75      0.77       394\n",
      "           3       0.69      0.79      0.74       392\n",
      "           4       0.85      0.84      0.85       385\n",
      "           5       0.86      0.81      0.84       395\n",
      "           6       0.82      0.92      0.87       390\n",
      "           7       0.92      0.92      0.92       396\n",
      "           8       0.97      0.95      0.96       398\n",
      "           9       0.94      0.94      0.94       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.95      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.92      0.91      0.91       394\n",
      "          15       0.88      0.92      0.90       398\n",
      "          16       0.77      0.92      0.84       364\n",
      "          17       0.98      0.91      0.94       376\n",
      "          18       0.83      0.63      0.72       310\n",
      "          19       0.73      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a. Lowercasing (true or false)\n",
    "# Create an empty list to store results\n",
    "results = []\n",
    "\n",
    "# 1. Test Lowercasing\n",
    "for lowercase in [True, False]:\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        max_df=0.5,\n",
    "        min_df=5,\n",
    "        lowercase=lowercase,\n",
    "        stop_words=\"english\",\n",
    "        analyzer='word',\n",
    "        ngram_range=(1, 1),\n",
    "        max_features=None\n",
    "    )\n",
    "    \n",
    "    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "    CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'Lowercasing',\n",
    "        'value': lowercase,\n",
    "        'accuracy': CMLPAcc,\n",
    "        'precision': CMLPPre,\n",
    "        'recall': CMLPRe,\n",
    "        'f1_score': CMLPF1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.479s at 8.895MB/s\n",
      "n_samples: 11314, n_features: 25914\n",
      "Vectorize testing done in 1.455s at 9.486MB/s\n",
      "n_samples: 7532, n_features: 25914\n",
      "MLP Accuracy: 0.8540\n",
      "MLP Precision: 0.8563\n",
      "MLP Recall: 0.8540\n",
      "MLP F1 Score: 0.8534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82       319\n",
      "           1       0.75      0.81      0.78       389\n",
      "           2       0.75      0.75      0.75       394\n",
      "           3       0.69      0.74      0.71       392\n",
      "           4       0.83      0.85      0.84       385\n",
      "           5       0.88      0.77      0.83       395\n",
      "           6       0.81      0.89      0.85       390\n",
      "           7       0.93      0.90      0.92       396\n",
      "           8       0.96      0.96      0.96       398\n",
      "           9       0.93      0.96      0.95       397\n",
      "          10       0.97      0.98      0.97       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.78      0.77      0.78       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.87      0.93      0.90       398\n",
      "          16       0.76      0.92      0.83       364\n",
      "          17       0.98      0.89      0.93       376\n",
      "          18       0.84      0.62      0.71       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.85      0.85      7532\n",
      "weighted avg       0.86      0.85      0.85      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.304s at 9.570MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.376s at 10.029MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Test Stop Words\n",
    "for stop_words in [None, 'english']:\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        max_df=0.5,\n",
    "        min_df=5,\n",
    "        lowercase=True,\n",
    "        stop_words=stop_words,\n",
    "        analyzer='word',\n",
    "        ngram_range=(1, 1),\n",
    "        max_features=None\n",
    "    )\n",
    "    \n",
    "    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "    CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'Stop Words',\n",
    "        'value': stop_words,\n",
    "        'accuracy': CMLPAcc,\n",
    "        'precision': CMLPPre,\n",
    "        'recall': CMLPRe,\n",
    "        'f1_score': CMLPF1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.310s at 9.549MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.326s at 10.406MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 4.982s at 4.427MB/s\n",
      "n_samples: 11314, n_features: 64194\n",
      "Vectorize testing done in 2.134s at 6.467MB/s\n",
      "n_samples: 7532, n_features: 64194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.8602\n",
      "MLP Precision: 0.8626\n",
      "MLP Recall: 0.8602\n",
      "MLP F1 Score: 0.8600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       319\n",
      "           1       0.74      0.84      0.78       389\n",
      "           2       0.77      0.78      0.78       394\n",
      "           3       0.74      0.76      0.75       392\n",
      "           4       0.82      0.84      0.83       385\n",
      "           5       0.86      0.80      0.83       395\n",
      "           6       0.80      0.90      0.85       390\n",
      "           7       0.93      0.89      0.91       396\n",
      "           8       0.95      0.95      0.95       398\n",
      "           9       0.92      0.95      0.94       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.93      0.92      0.93       396\n",
      "          12       0.79      0.78      0.79       393\n",
      "          13       0.88      0.87      0.88       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.88      0.93      0.90       398\n",
      "          16       0.81      0.93      0.86       364\n",
      "          17       0.98      0.90      0.94       376\n",
      "          18       0.88      0.67      0.76       310\n",
      "          19       0.76      0.72      0.74       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.86      0.86      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:547: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.979s at 7.403MB/s\n",
      "n_samples: 11314, n_features: 28\n",
      "Vectorize testing done in 3.032s at 4.551MB/s\n",
      "n_samples: 7532, n_features: 28\n"
     ]
    }
   ],
   "source": [
    "# 3. Test Analyzer and Ngram Range\n",
    "for analyzer in ['word', 'char']:\n",
    "    for ngram_range in [(1, 1), (1, 2)]:\n",
    "        tfidf_vectorizer = TfidfVectorizer(\n",
    "            sublinear_tf=True,\n",
    "            max_df=0.5,\n",
    "            min_df=5,\n",
    "            lowercase=True,\n",
    "            stop_words='english',\n",
    "            analyzer=analyzer,\n",
    "            ngram_range=ngram_range,\n",
    "            max_features=None\n",
    "        )\n",
    "        \n",
    "        X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "        CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "        \n",
    "        results.append({\n",
    "            'test': 'Analyzer and Ngram Range',\n",
    "            'analyzer': analyzer,\n",
    "            'ngram_range': ngram_range,\n",
    "            'accuracy': CMLPAcc,\n",
    "            'precision': CMLPPre,\n",
    "            'recall': CMLPRe,\n",
    "            'f1_score': CMLPF1\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.739s at 8.052MB/s\n",
      "n_samples: 11314, n_features: 25631\n",
      "Vectorize testing done in 1.636s at 8.433MB/s\n",
      "n_samples: 7532, n_features: 25631\n",
      "MLP Accuracy: 0.8586\n",
      "MLP Precision: 0.8613\n",
      "MLP Recall: 0.8586\n",
      "MLP F1 Score: 0.8582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       319\n",
      "           1       0.75      0.83      0.79       389\n",
      "           2       0.80      0.74      0.77       394\n",
      "           3       0.68      0.78      0.73       392\n",
      "           4       0.82      0.86      0.84       385\n",
      "           5       0.87      0.80      0.83       395\n",
      "           6       0.83      0.88      0.86       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.97      0.96      0.96       398\n",
      "           9       0.94      0.96      0.95       397\n",
      "          10       0.97      0.98      0.98       399\n",
      "          11       0.94      0.94      0.94       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.91      0.91       394\n",
      "          15       0.86      0.93      0.90       398\n",
      "          16       0.77      0.92      0.83       364\n",
      "          17       0.99      0.90      0.94       376\n",
      "          18       0.84      0.63      0.72       310\n",
      "          19       0.75      0.68      0.71       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.85      0.85      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.809s at 7.851MB/s\n",
      "n_samples: 11314, n_features: 1000\n",
      "Vectorize testing done in 1.736s at 7.948MB/s\n",
      "n_samples: 7532, n_features: 1000\n",
      "MLP Accuracy: 0.6470\n",
      "MLP Precision: 0.6519\n",
      "MLP Recall: 0.6470\n",
      "MLP F1 Score: 0.6483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61       319\n",
      "           1       0.59      0.59      0.59       389\n",
      "           2       0.58      0.57      0.58       394\n",
      "           3       0.49      0.49      0.49       392\n",
      "           4       0.59      0.64      0.62       385\n",
      "           5       0.65      0.64      0.64       395\n",
      "           6       0.73      0.75      0.74       390\n",
      "           7       0.64      0.69      0.67       396\n",
      "           8       0.74      0.77      0.75       398\n",
      "           9       0.73      0.69      0.71       397\n",
      "          10       0.81      0.84      0.82       399\n",
      "          11       0.85      0.78      0.81       396\n",
      "          12       0.42      0.44      0.43       393\n",
      "          13       0.58      0.57      0.57       396\n",
      "          14       0.77      0.76      0.76       394\n",
      "          15       0.78      0.74      0.76       398\n",
      "          16       0.60      0.68      0.64       364\n",
      "          17       0.87      0.67      0.75       376\n",
      "          18       0.51      0.46      0.48       310\n",
      "          19       0.38      0.43      0.40       251\n",
      "\n",
      "    accuracy                           0.65      7532\n",
      "   macro avg       0.64      0.64      0.64      7532\n",
      "weighted avg       0.65      0.65      0.65      7532\n",
      "\n",
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 2.738s at 8.055MB/s\n",
      "n_samples: 11314, n_features: 5000\n",
      "Vectorize testing done in 1.571s at 8.782MB/s\n",
      "n_samples: 7532, n_features: 5000\n",
      "MLP Accuracy: 0.8099\n",
      "MLP Precision: 0.8130\n",
      "MLP Recall: 0.8099\n",
      "MLP F1 Score: 0.8097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       319\n",
      "           1       0.69      0.76      0.72       389\n",
      "           2       0.76      0.71      0.73       394\n",
      "           3       0.63      0.71      0.66       392\n",
      "           4       0.81      0.80      0.81       385\n",
      "           5       0.83      0.75      0.79       395\n",
      "           6       0.80      0.87      0.83       390\n",
      "           7       0.85      0.87      0.86       396\n",
      "           8       0.92      0.92      0.92       398\n",
      "           9       0.93      0.91      0.92       397\n",
      "          10       0.95      0.97      0.96       399\n",
      "          11       0.96      0.91      0.93       396\n",
      "          12       0.67      0.69      0.68       393\n",
      "          13       0.83      0.81      0.82       396\n",
      "          14       0.87      0.90      0.88       394\n",
      "          15       0.83      0.89      0.86       398\n",
      "          16       0.72      0.87      0.79       364\n",
      "          17       0.98      0.84      0.90       376\n",
      "          18       0.74      0.55      0.63       310\n",
      "          19       0.61      0.59      0.60       251\n",
      "\n",
      "    accuracy                           0.81      7532\n",
      "   macro avg       0.81      0.80      0.80      7532\n",
      "weighted avg       0.81      0.81      0.81      7532\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     17\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Features\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: max_features,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m: CMLPF1\n\u001b[0;32m     24\u001b[0m     })\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Convert the results list to a DataFrame\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Test Max Features\n",
    "for max_features in [None, 1000, 5000]:\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        max_df=0.5,\n",
    "        min_df=5,\n",
    "        lowercase=True,\n",
    "        stop_words='english',\n",
    "        analyzer='word',\n",
    "        ngram_range=(1, 1),\n",
    "        max_features=max_features\n",
    "    )\n",
    "    \n",
    "    X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "    CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'Max Features',\n",
    "        'value': max_features,\n",
    "        'accuracy': CMLPAcc,\n",
    "        'precision': CMLPPre,\n",
    "        'recall': CMLPRe,\n",
    "        'f1_score': CMLPF1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        test    value  accuracy  precision    recall  \\\n",
      "0                Lowercasing     True  0.858603   0.861315  0.858603   \n",
      "1                Lowercasing    False  0.858471   0.861084  0.858471   \n",
      "2                 Stop Words     None  0.853956   0.856261  0.853956   \n",
      "3                 Stop Words  english  0.858603   0.861315  0.858603   \n",
      "4   Analyzer and Ngram Range      NaN  0.858603   0.861315  0.858603   \n",
      "5   Analyzer and Ngram Range      NaN  0.860860   0.863019  0.860860   \n",
      "6   Analyzer and Ngram Range      NaN  0.159984   0.154684  0.159984   \n",
      "7   Analyzer and Ngram Range      NaN  0.637812   0.642718  0.637812   \n",
      "8               Max Features     None  0.858603   0.861315  0.858603   \n",
      "9               Max Features     1000  0.646973   0.651936  0.646973   \n",
      "10              Max Features     5000  0.809878   0.813018  0.809878   \n",
      "\n",
      "    f1_score analyzer ngram_range  \n",
      "0   0.858213      NaN         NaN  \n",
      "1   0.858194      NaN         NaN  \n",
      "2   0.853414      NaN         NaN  \n",
      "3   0.858213      NaN         NaN  \n",
      "4   0.858213     word      (1, 1)  \n",
      "5   0.860604     word      (1, 2)  \n",
      "6   0.146551     char      (1, 1)  \n",
      "7   0.639190     char      (1, 2)  \n",
      "8   0.858213      NaN         NaN  \n",
      "9   0.648300      NaN         NaN  \n",
      "10  0.809660      NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.05MB (training set)\n",
      "7532 documents - 13.80MB (test set)\n",
      "20 categories\n",
      "Vectorize training done in 5.090s at 4.333MB/s\n",
      "n_samples: 11314, n_features: 64194\n",
      "Vectorize testing done in 2.197s at 6.282MB/s\n",
      "n_samples: 7532, n_features: 64194\n",
      "MLP Accuracy: 0.8609\n",
      "MLP Precision: 0.8630\n",
      "MLP Recall: 0.8609\n",
      "MLP F1 Score: 0.8606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83       319\n",
      "           1       0.75      0.82      0.78       389\n",
      "           2       0.78      0.77      0.78       394\n",
      "           3       0.73      0.76      0.74       392\n",
      "           4       0.82      0.84      0.83       385\n",
      "           5       0.87      0.81      0.83       395\n",
      "           6       0.82      0.89      0.86       390\n",
      "           7       0.92      0.90      0.91       396\n",
      "           8       0.95      0.96      0.96       398\n",
      "           9       0.93      0.95      0.94       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.95      0.93      0.94       396\n",
      "          12       0.77      0.80      0.79       393\n",
      "          13       0.88      0.87      0.87       396\n",
      "          14       0.90      0.91      0.91       394\n",
      "          15       0.87      0.92      0.90       398\n",
      "          16       0.80      0.93      0.86       364\n",
      "          17       0.98      0.90      0.94       376\n",
      "          18       0.87      0.67      0.76       310\n",
      "          19       0.76      0.73      0.74       251\n",
      "\n",
      "    accuracy                           0.86      7532\n",
      "   macro avg       0.86      0.86      0.86      7532\n",
      "weighted avg       0.86      0.86      0.86      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimal combination\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True, \n",
    "    max_df=0.5, \n",
    "    min_df=5, \n",
    "    stop_words=\"english\", \n",
    "    ngram_range=(1, 2),\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, feature_names_tfidf, target_names_tfidf = load_dataset(tfidf_vectorizer, verbose=True)\n",
    "CMLPAcc, CMLPPre, CMLPRe, CMLPF1 = classify_and_print_results(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, \"MLP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8608603292618162 0.8630192877572318 0.8608603292618162 0.8606036212727489\n"
     ]
    }
   ],
   "source": [
    "print(CMLPAcc, CMLPPre, CMLPRe, CMLPF1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
