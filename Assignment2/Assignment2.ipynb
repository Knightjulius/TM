{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ztJoT_2HWcJ"
   },
   "source": [
    "# Text mining assignment 2 (Emma Vonk and Julius Ruijgrok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l-M5asKdHWcT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_-P4OwivyYL"
   },
   "source": [
    "# Question 2\n",
    "Convert the IOB data to the correct data structure for token classification in Huggingface\n",
    "(words and labels like the conll2023 data in the tutorial) and align the labels with the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hDMtXFXHHWcU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 1992/1992 [00:00<00:00, 192189.49 examples/s]\n",
      "Casting the dataset: 100%|██████████| 850/850 [00:00<00:00, 192867.64 examples/s]\n",
      "Casting the dataset: 100%|██████████| 864/864 [00:00<00:00, 151341.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to make the dataset to the correct huggingface structure explained in: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "\n",
    "\n",
    "def read_bio_file(filepath):\n",
    "    sentences = []\n",
    "    current_sentence = {\"tokens\": [], \"ner_tags\": [], \"pos_tags\": []}\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if current_sentence[\"tokens\"]:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = {\"tokens\": [], \"ner_tags\": [], \"pos_tags\": []}\n",
    "            else:\n",
    "                token, pos, label = line.split()  # Each line is a token POS-label\n",
    "                current_sentence[\"tokens\"].append(token)\n",
    "                # Map labels to an integer ID\n",
    "                current_sentence[\"ner_tags\"].append(label_to_id(label))\n",
    "                current_sentence[\"pos_tags\"].append(pos)\n",
    "\n",
    "        # Add the last sentence if file doesn't end with a blank line\n",
    "        if current_sentence[\"tokens\"]:\n",
    "            sentences.append(current_sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def label_to_id(label):\n",
    "    # This function should map each label to a unique integer (e.g., B-PER -> 0, I-PER -> 1, O -> 2).\n",
    "    label_mapping = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4, 'B-ART': 5, 'I-ART': 6, 'I-MAT': 7, 'B-MAT': 8, 'I-CON': 9, 'B-CON': 10, 'I-SPE': 11, 'B-SPE': 12}\n",
    "    return label_mapping.get(label, -100)  # Return -100 for unknown labels\n",
    "\n",
    "# Read datasets\n",
    "train_data = read_bio_file(\"train.txt\")\n",
    "val_data = read_bio_file(\"val.txt\")\n",
    "test_data = read_bio_file(\"test.txt\")\n",
    "\n",
    "# Load into HuggingFace dataset structure\n",
    "dataset = datasets.DatasetDict({\n",
    "    \"train\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in train_data], \"ner_tags\": [d[\"ner_tags\"] for d in train_data], \"pos_tags\": [d[\"pos_tags\"] for d in train_data]}),\n",
    "    \"validation\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in val_data], \"ner_tags\": [d[\"ner_tags\"] for d in val_data], \"pos_tags\": [d[\"pos_tags\"] for d in val_data]}),\n",
    "    \"test\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in test_data], \"ner_tags\": [d[\"ner_tags\"] for d in test_data], \"pos_tags\": [d[\"pos_tags\"] for d in test_data\n",
    "                                                                                                                                                ]})\n",
    "})\n",
    "\n",
    "# Define label mapping\n",
    "label_names = ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ART', 'I-ART', 'I-MAT', 'B-MAT', 'I-CON', 'B-CON', 'I-SPE', 'B-SPE']\n",
    "\n",
    "# Create the ClassLabel feature with only the names (otherwise the number does not overlap)\n",
    "ner_feature = datasets.ClassLabel(names=label_names)\n",
    "\n",
    "dataset = dataset.cast_column(\"ner_tags\", datasets.Sequence(ner_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Gua40EeHHWcW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'pos_tags'],\n",
       "        num_rows: 1992\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'pos_tags'],\n",
       "        num_rows: 850\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'pos_tags'],\n",
       "        num_rows: 864\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the structure of the data\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aXGdQMinHWcY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1992 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1992/1992 [00:00<00:00, 6182.23 examples/s]\n",
      "Map: 100%|██████████| 850/850 [00:00<00:00, 9442.45 examples/s]\n",
      "Map: 100%|██████████| 864/864 [00:00<00:00, 9386.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "\n",
    "# Pre-processing the data and tokenize\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk39Kgihyfzb"
   },
   "source": [
    "Now, the pre-processing of the data is finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awMovOGeHWcZ"
   },
   "source": [
    "# Question 3\n",
    "Fine-tune a model with the default hyperparameter settings on the train set and evaluate the model on the test set. These are your baseline results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QWedt7uYHWca"
   },
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "f9s63bOIHWca"
   },
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "m8i_UL6FHWcb"
   },
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "D5BX-_tPHWcb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
    "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
    "num_epochs = 3\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  1/125 [..............................] - ETA: 3:28:12 - loss: 2.5778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "predictions = labels.copy()\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ART': {'precision': 0.0012406947890818859,\n",
       "  'recall': 0.005952380952380952,\n",
       "  'f1': 0.002053388090349076,\n",
       "  'number': 168},\n",
       " 'CON': {'precision': 0.01098901098901099,\n",
       "  'recall': 0.004629629629629629,\n",
       "  'f1': 0.006514657980456026,\n",
       "  'number': 216},\n",
       " 'LOC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 144},\n",
       " 'MAT': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 107},\n",
       " 'PER': {'precision': 0.0025614754098360654,\n",
       "  'recall': 0.0176678445229682,\n",
       "  'f1': 0.0044742729306487695,\n",
       "  'number': 283},\n",
       " 'SPE': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2},\n",
       " 'overall_precision': 0.0010149340292880964,\n",
       " 'overall_recall': 0.007608695652173913,\n",
       " 'overall_f1': 0.0017909684022003327,\n",
       " 'overall_accuracy': 0.6252288538996704}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "label_names = ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ART', 'I-ART', 'I-MAT', 'B-MAT', 'I-CON', 'B-CON', 'I-SPE', 'B-SPE']\n",
    "\n",
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import numpy as np\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2VpKNPsHWcc"
   },
   "source": [
    "# Question 4\n",
    "Set up hyperparameter optimization (HPO), use the val set as validation. Optimize at least three hyperparameters (learning rate, batch size and weight decay). You can choose your own way to implement this and select your own grid. After the model has been optimized, evaluate the result on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliu\\AppData\\Local\\Temp\\ipykernel_20908\\2666756663.py:62: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   learning_rate batch_size  weight_decay  val_loss\n",
      "0        0.00001          8          0.01  0.254255\n",
      "Best hyperparameters: learning_rate     0.00001\n",
      "batch_size              8\n",
      "weight_decay         0.01\n",
      "val_loss         0.254255\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define hyperparameter grids\n",
    "#learning_rates = [1e-5, 2e-5, 3e-5]\n",
    "#batch_sizes = [8, 16, 32]\n",
    "#weight_decays = [0.01, 0.001, 0.0001]\n",
    "\n",
    "# TODO remove this after it works\n",
    "learning_rates = [1e-5]\n",
    "batch_sizes = [8]\n",
    "weight_decays = [0.01]\n",
    "num_epochs = 1\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=[\"learning_rate\", \"batch_size\", \"weight_decay\", \"val_loss\"])\n",
    "\n",
    "# Hyperparameter optimization loop\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for weight_decay in weight_decays:\n",
    "            # Create tf datasets with the current batch size\n",
    "            tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "                columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "                collate_fn=data_collator,\n",
    "                shuffle=True,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "            tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "                columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "                collate_fn=data_collator,\n",
    "                shuffle=False,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "\n",
    "            # Set up optimizer with the current learning rate and weight decay\n",
    "            optimizer, schedule = create_optimizer(\n",
    "                init_lr=lr,\n",
    "                num_warmup_steps=0,\n",
    "                num_train_steps=len(tf_train_dataset) * num_epochs,\n",
    "                weight_decay_rate=weight_decay,\n",
    "            )\n",
    "            model.compile(optimizer=optimizer)\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                tf_train_dataset,\n",
    "                validation_data=tf_eval_dataset,\n",
    "                epochs=num_epochs,\n",
    "                verbose=0  # Suppress detailed training output for readability\n",
    "            )\n",
    "\n",
    "            # Get the validation loss for the final epoch\n",
    "            val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "            # Append the results as a new DataFrame and concatenate\n",
    "            new_row = pd.DataFrame({\n",
    "                \"learning_rate\": [lr],\n",
    "                \"batch_size\": [batch_size],\n",
    "                \"weight_decay\": [weight_decay],\n",
    "                \"val_loss\": [val_loss]\n",
    "            })\n",
    "            results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Display all results\n",
    "print(results)\n",
    "\n",
    "# After optimization, evaluate on test set with best hyperparameters\n",
    "best_params = results.loc[results['val_loss'].idxmin()]\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train with best hyperparameters and evaluate on test set\n",
    "best_lr = best_params[\"learning_rate\"]\n",
    "best_batch_size = int(best_params[\"batch_size\"])\n",
    "best_weight_decay = best_params[\"weight_decay\"]\n",
    "\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=best_batch_size,\n",
    ")\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=best_batch_size,\n",
    ")\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=best_lr,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=len(tf_train_dataset) * num_epochs,\n",
    "    weight_decay_rate=best_weight_decay,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "model.fit(tf_train_dataset, epochs=num_epochs, verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate on test set\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "\n",
    "test_metric = metric.compute(predictions=[all_predictions], references=[all_labels])\n",
    "print(\"Test set performance:\", test_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Extend the evaluation function so that it shows the Precision, Recall and F-score for each of the entity types (location, artefact, etc.) on the test set. Include the metrics for the B-label of the entity type, the I-label, and the full entities.\n",
    "\n",
    "# Question 6\n",
    "Look up the definitions of macro- and micro-average scores and compute the macro- and micro average F1 scores over all entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "m1yyWYG6HWcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ART': {'precision': 0.32142857142857145,\n",
       "  'recall': 0.5357142857142857,\n",
       "  'f1': 0.4017857142857143,\n",
       "  'number': 252},\n",
       " 'CON': {'precision': 0.30869565217391304,\n",
       "  'recall': 0.6068376068376068,\n",
       "  'f1': 0.40922190201729103,\n",
       "  'number': 234},\n",
       " 'LOC': {'precision': 0.5603448275862069,\n",
       "  'recall': 0.436241610738255,\n",
       "  'f1': 0.49056603773584906,\n",
       "  'number': 149},\n",
       " 'MAT': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 70},\n",
       " 'PER': {'precision': 0.6140350877192983,\n",
       "  'recall': 0.7270029673590505,\n",
       "  'f1': 0.6657608695652174,\n",
       "  'number': 337},\n",
       " 'SPE': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 59},\n",
       " 'overall_precision': 0.42078853046594983,\n",
       " 'overall_recall': 0.5331516802906449,\n",
       " 'overall_f1': 0.47035256410256415,\n",
       " 'overall_accuracy': 0.9316645588940735}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import numpy as np\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_eval_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uQdncSs_HWce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "Precision: 0.4807\n",
      "Recall: 0.5815\n",
      "F1-Score: 0.5263\n",
      "Accuracy: 0.9492\n",
      "\n",
      "Per-Entity Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART       0.37      0.61      0.46       168\n",
      "         CON       0.35      0.59      0.44       216\n",
      "         LOC       0.59      0.59      0.59       144\n",
      "         MAT       0.00      0.00      0.00       107\n",
      "         PER       0.66      0.78      0.72       283\n",
      "         SPE       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.48      0.58      0.53       920\n",
      "   macro avg       0.33      0.43      0.37       920\n",
      "weighted avg       0.45      0.58      0.50       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from seqeval.metrics import classification_report as seqeval_classification_report\n",
    "\n",
    "# Load seqeval metric\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate on the test set\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    batch_labels = batch[\"labels\"].numpy()  # Avoid overwriting variable 'labels'\n",
    "    batch_predictions = np.argmax(logits, axis=-1)  # Avoid overwriting variable 'predictions'\n",
    "\n",
    "    for pred, true_label in zip(batch_predictions, batch_labels):\n",
    "        pred_sequence = []\n",
    "        label_sequence = []\n",
    "        for predicted_idx, label_idx in zip(pred, true_label):\n",
    "            if label_idx == -100:  # Skip padding\n",
    "                continue\n",
    "            pred_label = label_names[predicted_idx]\n",
    "            true_label_str = label_names[label_idx]\n",
    "            pred_sequence.append(pred_label)\n",
    "            label_sequence.append(true_label_str)\n",
    "        all_predictions.append(pred_sequence)\n",
    "        all_labels.append(label_sequence)\n",
    "\n",
    "# Compute overall metrics\n",
    "results = metric.compute(predictions=all_predictions, references=all_labels)\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "print(f\"Precision: {results['overall_precision']:.4f}\")\n",
    "print(f\"Recall: {results['overall_recall']:.4f}\")\n",
    "print(f\"F1-Score: {results['overall_f1']:.4f}\")\n",
    "print(f\"Accuracy: {results['overall_accuracy']:.4f}\")\n",
    "\n",
    "# Use seqeval's classification_report to get detailed per-entity metrics\n",
    "print(\"\\nPer-Entity Metrics:\")\n",
    "print(seqeval_classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in the training set:\n",
      "O: 57424\n",
      "B-ART: 1000\n",
      "I-ART: 965\n",
      "B-PER: 1213\n",
      "I-PER: 1631\n",
      "B-CON: 1423\n",
      "B-MAT: 185\n",
      "I-MAT: 26\n",
      "I-CON: 153\n",
      "B-LOC: 342\n",
      "I-LOC: 679\n",
      "B-SPE: 184\n",
      "I-SPE: 9\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count label occurrences in the training dataset\n",
    "label_counter = Counter()\n",
    "for batch in tf_train_dataset:\n",
    "    labels = batch[\"labels\"].numpy()\n",
    "    for label_seq in labels:\n",
    "        for label in label_seq:\n",
    "            if label != -100:  # Exclude padding labels\n",
    "                label_counter[label_names[label]] += 1\n",
    "\n",
    "print(\"Label distribution in the training set:\")\n",
    "for label, count in label_counter.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
