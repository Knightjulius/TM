{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ztJoT_2HWcJ"
   },
   "source": [
    "# Text mining assignment 2 (Emma Vonk and Julius Ruijgrok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l-M5asKdHWcT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_-P4OwivyYL"
   },
   "source": [
    "# Question 2\n",
    "Convert the IOB data to the correct data structure for token classification in Huggingface\n",
    "(words and labels like the conll2023 data in the tutorial) and align the labels with the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hDMtXFXHHWcU"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb1b8285e1b49f09cf505498012a900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c1cedceffc498897f184ee1089c070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bca6ad71db404c8c871f4f6e51ec3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to make the dataset to the correct huggingface structure explained in: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "\n",
    "\n",
    "def read_bio_file(filepath):\n",
    "    sentences = []\n",
    "    current_sentence = {\"tokens\": [], \"ner_tags\": [], \"pos_tags\": []}\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if current_sentence[\"tokens\"]:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = {\"tokens\": [], \"ner_tags\": [], \"pos_tags\": []}\n",
    "            else:\n",
    "                token, pos, label = line.split()  # Each line is a token POS-label\n",
    "                current_sentence[\"tokens\"].append(token)\n",
    "                # Map labels to an integer ID\n",
    "                current_sentence[\"ner_tags\"].append(label_to_id(label))\n",
    "                current_sentence[\"pos_tags\"].append(pos)\n",
    "\n",
    "        # Add the last sentence if file doesn't end with a blank line\n",
    "        if current_sentence[\"tokens\"]:\n",
    "            sentences.append(current_sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def label_to_id(label):\n",
    "    # This function should map each label to a unique integer (e.g., B-PER -> 0, I-PER -> 1, O -> 2).\n",
    "    label_mapping = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4, 'B-ART': 5, 'I-ART': 6, 'I-MAT': 7, 'B-MAT': 8, 'I-CON': 9, 'B-CON': 10, 'I-SPE': 11, 'B-SPE': 12}\n",
    "    return label_mapping.get(label, -100)  # Return -100 for unknown labels\n",
    "\n",
    "# Read datasets\n",
    "train_data = read_bio_file(\"train.txt\")\n",
    "val_data = read_bio_file(\"val.txt\")\n",
    "test_data = read_bio_file(\"test.txt\")\n",
    "\n",
    "# Load into HuggingFace dataset structure\n",
    "dataset = datasets.DatasetDict({\n",
    "    \"train\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in train_data], \"ner_tags\": [d[\"ner_tags\"] for d in train_data], \"pos_tags\": [d[\"pos_tags\"] for d in train_data]}),\n",
    "    \"validation\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in val_data], \"ner_tags\": [d[\"ner_tags\"] for d in val_data], \"pos_tags\": [d[\"pos_tags\"] for d in val_data]}),\n",
    "    \"test\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in test_data], \"ner_tags\": [d[\"ner_tags\"] for d in test_data], \"pos_tags\": [d[\"pos_tags\"] for d in test_data\n",
    "                                                                                                                                                ]})\n",
    "})\n",
    "\n",
    "# Define label mapping\n",
    "label_names = ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ART', 'I-ART', 'I-MAT', 'B-MAT', 'I-CON', 'B-CON', 'I-SPE', 'B-SPE']\n",
    "\n",
    "# Create the ClassLabel feature with only the names (otherwise the number does not overlap)\n",
    "ner_feature = datasets.ClassLabel(names=label_names)\n",
    "\n",
    "dataset = dataset.cast_column(\"ner_tags\", datasets.Sequence(ner_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Gua40EeHHWcW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'pos_tags'],\n",
       "        num_rows: 1992\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'pos_tags'],\n",
       "        num_rows: 850\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'pos_tags'],\n",
       "        num_rows: 864\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the structure of the data\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aXGdQMinHWcY"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5f20e2fb73496381554f4e2c9f5be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56b4294cc2b49cba727ef8000cda998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d9d60fd3c348dbbb408d2f9b2bf8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "\n",
    "# Pre-processing the data and tokenize\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk39Kgihyfzb"
   },
   "source": [
    "Now, the pre-processing of the data is finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awMovOGeHWcZ"
   },
   "source": [
    "# Question 3\n",
    "Fine-tune a model with the default hyperparameter settings on the train set and evaluate the model on the test set. These are your baseline results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QWedt7uYHWca"
   },
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "f9s63bOIHWca"
   },
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "m8i_UL6FHWcb"
   },
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "D5BX-_tPHWcb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
    "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
    "num_epochs = 3\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "125/125 [==============================] - 1182s 9s/step - loss: 0.4969 - val_loss: 0.2784\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 1051s 8s/step - loss: 0.1566 - val_loss: 0.2392\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 1022s 8s/step - loss: 0.1124 - val_loss: 0.2475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2049c3e2850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "predictions = labels.copy()\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ART': {'precision': 0.35074626865671643,\n",
       "  'recall': 0.5595238095238095,\n",
       "  'f1': 0.4311926605504587,\n",
       "  'number': 168},\n",
       " 'CON': {'precision': 0.3875,\n",
       "  'recall': 0.5740740740740741,\n",
       "  'f1': 0.4626865671641791,\n",
       "  'number': 216},\n",
       " 'LOC': {'precision': 0.5439560439560439,\n",
       "  'recall': 0.6875,\n",
       "  'f1': 0.6073619631901841,\n",
       "  'number': 144},\n",
       " 'MAT': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 107},\n",
       " 'PER': {'precision': 0.7529761904761905,\n",
       "  'recall': 0.8939929328621908,\n",
       "  'f1': 0.8174474959612278,\n",
       "  'number': 283},\n",
       " 'SPE': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2},\n",
       " 'overall_precision': 0.5144404332129964,\n",
       " 'overall_recall': 0.6195652173913043,\n",
       " 'overall_f1': 0.5621301775147929,\n",
       " 'overall_accuracy': 0.9561058220432076}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "label_names = ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ART', 'I-ART', 'I-MAT', 'B-MAT', 'I-CON', 'B-CON', 'I-SPE', 'B-SPE']\n",
    "\n",
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import numpy as np\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2VpKNPsHWcc"
   },
   "source": [
    "# Question 4\n",
    "Set up hyperparameter optimization (HPO), use the val set as validation. Optimize at least three hyperparameters (learning rate, batch size and weight decay). You can choose your own way to implement this and select your own grid. After the model has been optimized, evaluate the result on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "125/125 [==============================] - 1098s 9s/step - loss: 0.5080 - val_loss: 0.3464\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 1035s 8s/step - loss: 0.2218 - val_loss: 0.2752\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 995s 8s/step - loss: 0.1667 - val_loss: 0.2655\n",
      "Test {n} out of 6 has concluded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliu\\AppData\\Local\\Temp\\ipykernel_17820\\2365670061.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "125/125 [==============================] - 1027s 8s/step - loss: 0.1379 - val_loss: 0.2417\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 995s 8s/step - loss: 0.0987 - val_loss: 0.2437\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 1000s 8s/step - loss: 0.0840 - val_loss: 0.2493\n",
      "Test {n} out of 6 has concluded\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 1191s 19s/step - loss: 0.0811 - val_loss: 0.2399\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1148s 18s/step - loss: 0.0653 - val_loss: 0.2400\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1160s 19s/step - loss: 0.0581 - val_loss: 0.2470\n",
      "Test {n} out of 6 has concluded\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 1209s 19s/step - loss: 0.0577 - val_loss: 0.2569\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1195s 19s/step - loss: 0.0471 - val_loss: 0.2679\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1222s 19s/step - loss: 0.0408 - val_loss: 0.2720\n",
      "Test {n} out of 6 has concluded\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 1052s 8s/step - loss: 0.0506 - val_loss: 0.2807\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 1039s 8s/step - loss: 0.0342 - val_loss: 0.3031\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 1049s 8s/step - loss: 0.0232 - val_loss: 0.3082\n",
      "Test {n} out of 6 has concluded\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 1060s 8s/step - loss: 0.0305 - val_loss: 0.3060\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 1029s 8s/step - loss: 0.0192 - val_loss: 0.3257\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 1036s 8s/step - loss: 0.0131 - val_loss: 0.3357\n",
      "Test {n} out of 6 has concluded\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 1249s 19s/step - loss: 0.0161 - val_loss: 0.3118\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1203s 19s/step - loss: 0.0114 - val_loss: 0.3305\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1218s 19s/step - loss: 0.0085 - val_loss: 0.3438\n",
      "Test {n} out of 6 has concluded\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 1226s 19s/step - loss: 0.0114 - val_loss: 0.3693\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1226s 18s/step - loss: 0.0074 - val_loss: 0.3704\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1208s 19s/step - loss: 0.0058 - val_loss: 0.3692\n",
      "Test {n} out of 6 has concluded\n",
      "   learning_rate batch_size  weight_decay  val_loss\n",
      "0        0.00001         16         0.010  0.265483\n",
      "1        0.00001         16         0.001  0.249348\n",
      "2        0.00001         32         0.010  0.246995\n",
      "3        0.00001         32         0.001  0.272050\n",
      "4        0.00002         16         0.010  0.308213\n",
      "5        0.00002         16         0.001  0.335678\n",
      "6        0.00002         32         0.010  0.343800\n",
      "7        0.00002         32         0.001  0.369150\n",
      "Best hyperparameters: learning_rate     0.00001\n",
      "batch_size             32\n",
      "weight_decay         0.01\n",
      "val_loss         0.246995\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#learning_rates = [1e-5, 2e-5, 3e-5]\n",
    "#batch_sizes = [8, 16, 32]\n",
    "#weight_decays = [0.01, 0.001, 0.0001]\n",
    "\n",
    "# Define hyperparameter grids\n",
    "learning_rates = [1e-5, 2e-5]\n",
    "batch_sizes = [16, 32]\n",
    "weight_decays = [0.01, 0.001]\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=[\"learning_rate\", \"batch_size\", \"weight_decay\", \"val_loss\"])\n",
    "n = 1\n",
    "# Hyperparameter optimization loop\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for weight_decay in weight_decays:\n",
    "            # Create tf datasets with the current batch size\n",
    "            tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "                columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "                collate_fn=data_collator,\n",
    "                shuffle=True,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "            tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "                columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "                collate_fn=data_collator,\n",
    "                shuffle=False,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "\n",
    "            # Set up optimizer with the current learning rate and weight decay\n",
    "            optimizer, schedule = create_optimizer(\n",
    "                init_lr=lr,\n",
    "                num_warmup_steps=0,\n",
    "                num_train_steps=len(tf_train_dataset) * num_epochs,\n",
    "                weight_decay_rate=weight_decay,\n",
    "            )\n",
    "            model.compile(optimizer=optimizer)\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                tf_train_dataset,\n",
    "                validation_data=tf_eval_dataset,\n",
    "                epochs=num_epochs,\n",
    "            )\n",
    "\n",
    "            # Get the validation loss for the final epoch\n",
    "            val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "            # Append the results as a new DataFrame and concatenate\n",
    "            new_row = pd.DataFrame({\n",
    "                \"learning_rate\": [lr],\n",
    "                \"batch_size\": [batch_size],\n",
    "                \"weight_decay\": [weight_decay],\n",
    "                \"val_loss\": [val_loss]\n",
    "            })\n",
    "            results = pd.concat([results, new_row], ignore_index=True)\n",
    "            print('Test {n} out of 6 has concluded')\n",
    "            n += 1\n",
    "\n",
    "# Display all results\n",
    "print(results)\n",
    "\n",
    "# After optimization, evaluate on test set with best hyperparameters\n",
    "best_params = results.loc[results['val_loss'].idxmin()]\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05 32 0.01\n",
      "Epoch 1/3\n",
      "63/63 [==============================] - 1278s 20s/step - loss: 0.0060 - val_loss: 0.3760\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1225s 20s/step - loss: 0.0048 - val_loss: 0.3965\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1219s 19s/step - loss: 0.0036 - val_loss: 0.3936\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_on_batch(batch)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     42\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 43\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(predictions, labels):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m predicted_idx, label_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(prediction, label):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-train with best hyperparameters and evaluate on test set\n",
    "best_lr = float(best_params[\"learning_rate\"])\n",
    "best_batch_size = int(best_params[\"batch_size\"])\n",
    "best_weight_decay = float(best_params[\"weight_decay\"])\n",
    "\n",
    "print(best_lr, best_batch_size, best_weight_decay)\n",
    "\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=best_batch_size,\n",
    ")\n",
    "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=best_batch_size,\n",
    ")\n",
    "\n",
    "            # Set up optimizer with the current learning rate and weight decay\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=best_lr,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=len(tf_train_dataset) * num_epochs,\n",
    "    weight_decay_rate=best_weight_decay,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    epochs=num_epochs,\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "\n",
    "test_metric = metric.compute(predictions=[all_predictions], references=[all_labels])\n",
    "print(\"Test set performance:\", test_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Extend the evaluation function so that it shows the Precision, Recall and F-score for each of the entity types (location, artefact, etc.) on the test set. Include the metrics for the B-label of the entity type, the I-label, and the full entities.\n",
    "\n",
    "# Question 6\n",
    "Look up the definitions of macro- and micro-average scores and compute the macro- and micro average F1 scores over all entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "m1yyWYG6HWcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ART': {'precision': 0.41643835616438357,\n",
       "  'recall': 0.6031746031746031,\n",
       "  'f1': 0.4927066450567262,\n",
       "  'number': 252},\n",
       " 'CON': {'precision': 0.37346437346437344,\n",
       "  'recall': 0.6495726495726496,\n",
       "  'f1': 0.4742589703588144,\n",
       "  'number': 234},\n",
       " 'LOC': {'precision': 0.6491228070175439,\n",
       "  'recall': 0.7449664429530202,\n",
       "  'f1': 0.6937500000000001,\n",
       "  'number': 149},\n",
       " 'MAT': {'precision': 0.43137254901960786,\n",
       "  'recall': 0.3142857142857143,\n",
       "  'f1': 0.3636363636363637,\n",
       "  'number': 70},\n",
       " 'PER': {'precision': 0.6634844868735084,\n",
       "  'recall': 0.8249258160237388,\n",
       "  'f1': 0.7354497354497354,\n",
       "  'number': 337},\n",
       " 'SPE': {'precision': 0.4945054945054945,\n",
       "  'recall': 0.7627118644067796,\n",
       "  'f1': 0.6,\n",
       "  'number': 59},\n",
       " 'overall_precision': 0.5053191489361702,\n",
       " 'overall_recall': 0.6902815622161671,\n",
       " 'overall_f1': 0.5834932821497122,\n",
       " 'overall_accuracy': 0.9422615673106275}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import numpy as np\n",
    "import evaluate\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_eval_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "uQdncSs_HWce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "Precision: 0.5683\n",
      "Recall: 0.7326\n",
      "F1-Score: 0.6401\n",
      "Accuracy: 0.9569\n",
      "\n",
      "Per-Entity Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART       0.48      0.66      0.56       168\n",
      "         CON       0.45      0.67      0.53       216\n",
      "         LOC       0.60      0.78      0.68       144\n",
      "         MAT       0.63      0.49      0.55       107\n",
      "         PER       0.71      0.89      0.79       283\n",
      "         SPE       0.10      0.50      0.17         2\n",
      "\n",
      "   micro avg       0.57      0.73      0.64       920\n",
      "   macro avg       0.50      0.67      0.55       920\n",
      "weighted avg       0.58      0.73      0.64       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from seqeval.metrics import classification_report as seqeval_classification_report\n",
    "\n",
    "# Load seqeval metric\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate on the test set\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    batch_labels = batch[\"labels\"].numpy()  # Avoid overwriting variable 'labels'\n",
    "    batch_predictions = np.argmax(logits, axis=-1)  # Avoid overwriting variable 'predictions'\n",
    "\n",
    "    for pred, true_label in zip(batch_predictions, batch_labels):\n",
    "        pred_sequence = []\n",
    "        label_sequence = []\n",
    "        for predicted_idx, label_idx in zip(pred, true_label):\n",
    "            if label_idx == -100:  # Skip padding\n",
    "                continue\n",
    "            pred_label = label_names[predicted_idx]\n",
    "            true_label_str = label_names[label_idx]\n",
    "            pred_sequence.append(pred_label)\n",
    "            label_sequence.append(true_label_str)\n",
    "        all_predictions.append(pred_sequence)\n",
    "        all_labels.append(label_sequence)\n",
    "\n",
    "# Compute overall metrics\n",
    "results = metric.compute(predictions=all_predictions, references=all_labels)\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "print(f\"Precision: {results['overall_precision']:.4f}\")\n",
    "print(f\"Recall: {results['overall_recall']:.4f}\")\n",
    "print(f\"F1-Score: {results['overall_f1']:.4f}\")\n",
    "print(f\"Accuracy: {results['overall_accuracy']:.4f}\")\n",
    "\n",
    "# Use seqeval's classification_report to get detailed per-entity metrics\n",
    "print(\"\\nPer-Entity Metrics:\")\n",
    "print(seqeval_classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in the training set:\n",
      "O: 57424\n",
      "B-ART: 1000\n",
      "I-ART: 965\n",
      "B-PER: 1213\n",
      "I-PER: 1631\n",
      "B-CON: 1423\n",
      "B-MAT: 185\n",
      "I-MAT: 26\n",
      "I-CON: 153\n",
      "B-LOC: 342\n",
      "I-LOC: 679\n",
      "B-SPE: 184\n",
      "I-SPE: 9\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count label occurrences in the training dataset\n",
    "label_counter = Counter()\n",
    "for batch in tf_train_dataset:\n",
    "    labels = batch[\"labels\"].numpy()\n",
    "    for label_seq in labels:\n",
    "        for label in label_seq:\n",
    "            if label != -100:  # Exclude padding labels\n",
    "                label_counter[label_names[label]] += 1\n",
    "\n",
    "print(\"Label distribution in the training set:\")\n",
    "for label, count in label_counter.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
