{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text mining assignment 2 (Emma Vonk and Julius Ruijgrok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the IOB data to the correct data structure for token classification in Huggingface (words and labels like the conll2023 data in the tutorial) and align the labels with the tokens. Note that since you are working with a custom dataset, the data conversion is a necessary step for using the Huggingface training function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make the dataset to the correct huggingface structure explained in: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "#\n",
    "def read_bio_file(filepath):\n",
    "    sentences = []\n",
    "    current_sentence = {\"tokens\": [], \"ner_tags\": []}\n",
    "    \n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if current_sentence[\"tokens\"]:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = {\"tokens\": [], \"ner_tags\": []}\n",
    "            else:\n",
    "                token, pos, label = line.split()  # Each line is a token POS-label\n",
    "                current_sentence[\"tokens\"].append(token)\n",
    "                # Map labels to an integer ID\n",
    "                current_sentence[\"ner_tags\"].append(label_to_id(label)) \n",
    "\n",
    "        # Add the last sentence if file doesn't end with a blank line\n",
    "        if current_sentence[\"tokens\"]:\n",
    "            sentences.append(current_sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def label_to_id(label):\n",
    "    # This function should map each label to a unique integer (e.g., B-PER -> 0, I-PER -> 1, O -> 2).\n",
    "    label_mapping = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4}\n",
    "    return label_mapping.get(label, -100)  # Return -100 for unknown labels\n",
    "\n",
    "# Read datasets\n",
    "train_data = read_bio_file(\"train.txt\")\n",
    "val_data = read_bio_file(\"val.txt\")\n",
    "test_data = read_bio_file(\"test.txt\")\n",
    "\n",
    "# Load into HuggingFace dataset structure\n",
    "dataset = datasets.DatasetDict({\n",
    "    \"train\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in train_data], \"ner_tags\": [d[\"ner_tags\"] for d in train_data]}),\n",
    "    \"validation\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in val_data], \"ner_tags\": [d[\"ner_tags\"] for d in val_data]}),\n",
    "    \"test\": datasets.Dataset.from_dict({\"tokens\": [d[\"tokens\"] for d in test_data], \"ner_tags\": [d[\"ner_tags\"] for d in test_data]}),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 1992\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 850\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 864\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)\n",
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "ner_feature = dataset[\"train\"].features[\"ner_tags\"]\n",
    "print(ner_feature)\n",
    "label_names = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 18 . \n",
      "O      O  O \n"
     ]
    }
   ],
   "source": [
    "words = dataset[\"train\"][0][\"tokens\"]\n",
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc684c54a3a74918abc2e5d5592f8ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e776c5027a742518bb37a581d1e6b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf5898a530d4065aa6b32b98f301bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune a model with the default hyperparameter settings on the train set and evaluate the model on the test set. These are your baseline results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "125/125 [==============================] - 1115s 9s/step - loss: 0.3593 - val_loss: 0.0844\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 1033s 8s/step - loss: 0.0301 - val_loss: 0.0634\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 1029s 8s/step - loss: 0.0177 - val_loss: 0.0693\n",
      "54/54 [==============================] - 90s 2s/step - loss: 0.0609\n",
      "Test set evaluation results: 0.06092755123972893\n"
     ]
    }
   ],
   "source": [
    "# TODO check how het zit met model trainen want vgm moet je die stap hierna hier al doen? als je niet compiled kan je niet trainen namelijk\n",
    "\n",
    "\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set training parameters\n",
    "num_train_steps = len(tf_train_dataset) * 3  # 3 epochs\n",
    "num_warmup_steps = num_train_steps // 10\n",
    "\n",
    "# Create an optimizer with default learning rate\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=5e-5, num_warmup_steps=num_warmup_steps, num_train_steps=num_train_steps\n",
    ")\n",
    "\n",
    "# Compile the model with default loss and optimizer\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Fine-tuning the model on the train set\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    epochs=3,\n",
    ")\n",
    "\n",
    "# Now, let's evaluate the model on the test set\n",
    "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = model.evaluate(tf_test_dataset)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test set evaluation results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\Juliu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ORG': {'precision': 0.6467065868263473,\n",
       "  'recall': 0.7248322147651006,\n",
       "  'f1': 0.6835443037974682,\n",
       "  'number': 149},\n",
       " 'PER': {'precision': 0.6915422885572139,\n",
       "  'recall': 0.8249258160237388,\n",
       "  'f1': 0.7523680649526386,\n",
       "  'number': 337},\n",
       " 'overall_precision': 0.6783831282952548,\n",
       " 'overall_recall': 0.7942386831275721,\n",
       " 'overall_f1': 0.7317535545023697,\n",
       " 'overall_accuracy': 0.9832358852548876}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "metric.compute(predictions=[predictions], references=[labels])\n",
    "\n",
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import numpy as np\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_eval_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameter optimization with the AdamW optimizer as explained in the tutorial. During optimization, use the val set as validation. After the model has been optimized, evaluate the result on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
    "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
    "num_epochs = 3\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "125/125 [==============================] - 1033s 8s/step - loss: 0.0183 - val_loss: 0.0807\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 1006s 8s/step - loss: 0.0093 - val_loss: 0.0793\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 999s 8s/step - loss: 0.0049 - val_loss: 0.0839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23682939d50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "# TODO check if this can be ignored, im doing it now lol and it still works\n",
    "#callback = PushToHubCallback(output_dir=\"bert-finetuned-ner\", tokenizer=tokenizer)\n",
    "\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    #callbacks=[callback],\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORG': {'precision': 0.6484848484848484,\n",
       "  'recall': 0.7181208053691275,\n",
       "  'f1': 0.6815286624203821,\n",
       "  'number': 149},\n",
       " 'PER': {'precision': 0.7012987012987013,\n",
       "  'recall': 0.8011869436201781,\n",
       "  'f1': 0.7479224376731302,\n",
       "  'number': 337},\n",
       " 'overall_precision': 0.6854545454545454,\n",
       " 'overall_recall': 0.7757201646090535,\n",
       " 'overall_f1': 0.7277992277992279,\n",
       " 'overall_accuracy': 0.9831445276813447}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code obtained from: https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt\n",
    "import numpy as np\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "for batch in tf_eval_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for predicted_idx, label_idx in zip(prediction, label):\n",
    "            if label_idx == -100:\n",
    "                continue\n",
    "            all_predictions.append(label_names[predicted_idx])\n",
    "            all_labels.append(label_names[label_idx])\n",
    "metric.compute(predictions=[all_predictions], references=[all_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the evaluation function so that it shows the Precision, Recall and F-score for each of the entity types (location, artefact, etc.) on the test set. Include the metrics for the B-label of the entity type, the I-label, and the full entities.\n",
    "\n",
    "Look up the definitions of macro- and micro-average scores and compute the macro- and micro average F1 scores over all entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "Precision: 0.7354\n",
      "Recall: 0.8525\n",
      "F1-Score: 0.7896\n",
      "Accuracy: 0.9856\n",
      "\n",
      "Per-Entity Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ORG       0.66      0.78      0.72       144\n",
      "         PER       0.77      0.89      0.83       283\n",
      "\n",
      "   micro avg       0.74      0.85      0.79       427\n",
      "   macro avg       0.72      0.83      0.77       427\n",
      "weighted avg       0.74      0.85      0.79       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from seqeval.metrics import classification_report as seqeval_classification_report\n",
    "\n",
    "# Load seqeval metric\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate on the test set\n",
    "for batch in tf_test_dataset:\n",
    "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
    "    batch_labels = batch[\"labels\"].numpy()  # Avoid overwriting variable 'labels'\n",
    "    batch_predictions = np.argmax(logits, axis=-1)  # Avoid overwriting variable 'predictions'\n",
    "\n",
    "    for pred, true_label in zip(batch_predictions, batch_labels):\n",
    "        pred_sequence = []\n",
    "        label_sequence = []\n",
    "        for predicted_idx, label_idx in zip(pred, true_label):\n",
    "            if label_idx == -100:  # Skip padding\n",
    "                continue\n",
    "            pred_label = label_names[predicted_idx]\n",
    "            true_label_str = label_names[label_idx]\n",
    "            pred_sequence.append(pred_label)\n",
    "            label_sequence.append(true_label_str)\n",
    "        all_predictions.append(pred_sequence)\n",
    "        all_labels.append(label_sequence)\n",
    "\n",
    "# Compute overall metrics\n",
    "results = metric.compute(predictions=all_predictions, references=all_labels)\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "print(f\"Precision: {results['overall_precision']:.4f}\")\n",
    "print(f\"Recall: {results['overall_recall']:.4f}\")\n",
    "print(f\"F1-Score: {results['overall_f1']:.4f}\")\n",
    "print(f\"Accuracy: {results['overall_accuracy']:.4f}\")\n",
    "\n",
    "# Use seqeval's classification_report to get detailed per-entity metrics\n",
    "print(\"\\nPer-Entity Metrics:\")\n",
    "print(seqeval_classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in the training set:\n",
      "O: 57424\n",
      "B-PER: 1213\n",
      "I-PER: 1631\n",
      "B-ORG: 342\n",
      "I-ORG: 679\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count label occurrences in the training dataset\n",
    "label_counter = Counter()\n",
    "for batch in tf_train_dataset:\n",
    "    labels = batch[\"labels\"].numpy()\n",
    "    for label_seq in labels:\n",
    "        for label in label_seq:\n",
    "            if label != -100:  # Exclude padding labels\n",
    "                label_counter[label_names[label]] += 1\n",
    "\n",
    "print(\"Label distribution in the training set:\")\n",
    "for label, count in label_counter.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# TODO er is ergens een grote imbalance zoals te zien is en die worden dus niet meegenomen in de training? \n",
    "# goed kijken naar hoe labels gedistribute worden en eventueel trainen met meer weight op de andere labels dan O?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
